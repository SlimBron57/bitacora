```yaml
Concepto: HumanRecognition Mini-LLM (BHR-v1)
Versi√≥n: 1.0
Fecha Creaci√≥n: 2025-11-29
√öltima Actualizaci√≥n: 2025-11-29 23:52:00
Autor: Eduardo GJ (propuesta original)
Prop√≥sito: Concepto de mini-LLM entrenado localmente para identificaci√≥n de personas
Estado: Dise√±o (v1.0-v2.0 telemetr√≠a) ‚Üí Implementaci√≥n (v2.5)
Tags: #ml #cost-optimization #local-inference #v2.5
Decisi√≥n: DA-TBD (pending formal approval)
```

# üß† HumanRecognition Mini-LLM (BHR-v1)

> **Subt√≠tulo**: *"Bit√°cora Human Recognition v1 - Mini-LLM entrenado con telemetr√≠a propia para identificaci√≥n local"*

> **Insight Eduardo (2025-11-29)**: "Recolectar par√°metros que enviamos a LLM ‚Üí entrenar nuestro propio mini-LLM ‚Üí costo casi $0"

---

## ‚ùì Qu√© Es

**HumanRecognition Mini-LLM** es un modelo de aprendizaje autom√°tico peque√±o (~100MB) entrenado espec√≠ficamente para la tarea de **identificaci√≥n de personas** en fotograf√≠as, usando como datos de entrenamiento la telemetr√≠a recolectada durante el uso real de Bit√°cora.

**NO es:**

- ‚ùå Vision LLM general (eso es GPT-4o, Gemini)
- ‚ùå Face recognition gen√©rico (eso es dlib, FaceNet)
- ‚ùå Cloud API (esto es 100% local)

**S√ç es:**

- ‚úÖ Mini-LLM especializado (single task: "Who is this?")
- ‚úÖ Entrenado con datos reales de usuarios Bit√°cora (opt-in)
- ‚úÖ Inferencia 100% local (0 cost per match)
- ‚úÖ Fallback a GPT-4o cuando baja confianza

---

## ü§î Por Qu√© Existe

### Problema Original

**Eduardo identifica (2025-11-29):**

```
An√°lisis de costos Bit√°cora v1.0:

Motor local: $2/month ‚úÖ
LLM APIs: $15/month ‚ö†Ô∏è

Total: $17/month
Target: $7-9/month

Problema: LLM es 7.5x m√°s caro que motor completo.
GPT-4o: $0.01 per image match (ongoing)
Uso esperado: 1,500 matches/month ‚Üí $15

¬øSoluci√≥n? Local inference ‚Üí $0 ongoing
```

**Eduardo pregunta:**

> "¬øPor qu√© no recolectar los par√°metros que enviamos al LLM,  
> entrenar nuestro propio mini-LLM,  
> y hacer matching 100% local?"

**Respuesta:** BHR-v1 (Bit√°cora Human Recognition v1)

### Motivaci√≥n Econ√≥mica

**Cost Model Comparison:**

| Strategy | Training Cost | Per-Match Cost | 500k Matches Lifetime | Monthly (1.5k) |
|----------|--------------|----------------|----------------------|----------------|
| **GPT-4o (cloud)** | $0 | $0.01 | $5,000 | $15 |
| **BHR-v1 (local)** | $50 one-time | $0 | $50 | $0 |

**Amortized cost:** $50 / 500,000 matches = **$0.0001 per match**

**Savings:** 98% reduction ($15/month ‚Üí $0/month after training)

**Break-even:** 5,000 matches (~3 months)

### Motivaci√≥n T√©cnica

**Ventajas adicionales:**

1. **Privacy**: 0 data leaves device (face embeddings 100% local)
2. **Speed**: No network latency (~50ms vs 2-3 seconds)
3. **Offline**: Works without internet
4. **Scalability**: Cost doesn't grow with users

---

## üèóÔ∏è C√≥mo Funciona

### Fase 1: Telemetr√≠a (v1.0-v2.0, 2026 Q1-Q2)

**Recolecci√≥n pasiva de par√°metros:**

```rust
// Cada vez que usuario confirma identidad
pub struct TelemetryEntry {
    // Vision LLM analysis (ya pagado)
    face_embedding: Vec<f32>,        // [512 dims]
    age_estimate: u8,
    gender_estimate: Gender,
    emotion_snapshot: Vec<String>,
    clothing_descriptors: Vec<String>,
    scene_context: String,
    
    // Usuario confirma
    confirmed_identity: String,      // "Mam√°", "Hermano Carlos"
    confidence_reported: f32,        // 0.0-1.0
    
    // Contexto conversacional
    conversation_themes: Vec<String>,
    emotional_space_label: String,
    
    // Metadata
    timestamp: DateTime<Utc>,
    user_id_anonymous: Hash,         // Anonymized
}

// Opci√≥n usuario
let telemetry_enabled = config.human_recognition.telemetry_enabled;
if telemetry_enabled {
    telemetry_db.append(entry)?;
}
```

**CONFIG_PARAMETERS:**

```toml
[human_recognition]
telemetry_enabled = true          # Opt-in (default false)
telemetry_retention_days = 365    # 1 year collection
telemetry_anonymous = true        # Hash user IDs
```

**Storage:**

- Local YAML: `~/.bitacora/telemetry/human_recognition.yaml`
- Size: ~500 bytes/entry ‚Üí 1,500 entries = 750KB
- **NO sale del dispositivo** sin consentimiento expl√≠cito

### Fase 2: Entrenamiento (v2.5, 2026 Q3)

**Proceso:**

1. **Aggregation** (Bit√°cora Corp):
   - Usuarios opt-in env√≠an telemetr√≠a (anonymized)
   - Bit√°cora Corp agrega 100k+ entries
   - Dataset: `{ face_embedding, context } ‚Üí identity_label`

2. **Training** (Cloud GPUs):
   - Architecture: Lightweight transformer (~100M params)
   - Task: Multi-class classification (top-20 people per user + "unknown")
   - Cost: $50 one-time (4h A100 GPU)

3. **Model Distribution**:
   - `bhr-v1.onnx` (100MB ONNX model)
   - Download via Bit√°cora updates
   - Stored: `~/.bitacora/models/bhr-v1.onnx`

**Training Pipeline:**

```python
# Pseudocode (not implemented yet)
def train_bhr_v1(telemetry_dataset):
    # Input: face_embedding [512] + context [128]
    # Output: identity probabilities [num_identities]
    
    model = LightweightTransformer(
        input_dims=640,          # 512 face + 128 context
        hidden_dims=256,
        num_layers=4,
        num_heads=8,
        output_classes=num_identities
    )
    
    # Train with cross-entropy loss
    optimizer = AdamW(lr=1e-4)
    train(model, telemetry_dataset, epochs=10)
    
    # Export to ONNX
    export_onnx(model, "bhr-v1.onnx")
```

### Fase 3: Inferencia (v2.5+, 2026 Q3+)

**Hybrid Matching Strategy:**

```rust
pub struct HumanRecognitionEngine {
    bhr_model: Option<BHRModel>,     // Local mini-LLM
    vision_llm: VisionLLMClient,     // GPT-4o fallback
    confidence_threshold: f32,        // 0.85 default
}

impl HumanRecognitionEngine {
    pub async fn identify_person(
        &self,
        face_embedding: &[f32],
        context: &ConversationContext,
    ) -> Result<IdentityMatch> {
        // 1. Try BHR-v1 (local, $0)
        if let Some(model) = &self.bhr_model {
            let prediction = model.predict(face_embedding, context)?;
            
            if prediction.confidence > self.confidence_threshold {
                return Ok(IdentityMatch {
                    identity: prediction.identity,
                    confidence: prediction.confidence,
                    method: MatchMethod::BHRLocal,
                });
            }
        }
        
        // 2. Fallback to Vision LLM (cloud, $0.01)
        let vision_result = self.vision_llm
            .identify_from_embedding(face_embedding, context)
            .await?;
            
        Ok(IdentityMatch {
            identity: vision_result.identity,
            confidence: vision_result.confidence,
            method: MatchMethod::VisionLLMFallback,
        })
    }
}
```

**Performance Target:**

- **BHR-v1 hit rate**: 85% (15% fallback to GPT-4o)
- **Effective cost**: $0 * 0.85 + $0.01 * 0.15 = **$0.0015/match**
- **vs GPT-4o only**: 85% savings even with fallback

---

## üìç D√≥nde Aparece

### Documentos Principales

#### 1. **18.4_bqm-identity-system-v1.md**
   - **Archivo**: [ROADMAP_V2/02_COMPONENTES/18.4_bqm-identity-system-v1.md](../../ROADMAP_V2/02_COMPONENTES/18.4_bqm-identity-system-v1.md)
   - **Secci√≥n**: "Future Evolution: HumanRecognition Mini-LLM"
   - **Rol**: Propuesta completa + cost analysis
   - **Lines**: ~720-780
   - **Contenido**:
     * Telemetry collection strategy
     * Training pipeline description
     * Cost model ($50 training / 500k matches)
     * Hybrid matching (BHR + GPT-4o fallback)

#### 2. **18.5_bqm-quantum-identity-vision-v2.md**
   - **Archivo**: [ROADMAP_V2/00_VISION/18.5_bqm-quantum-identity-vision-v2.md](../../ROADMAP_V2/00_VISION/18.5_bqm-quantum-identity-vision-v2.md)
   - **Secci√≥n**: Menciones v2.5
   - **Rol**: Roadmap positioning (v2.5 feature)
   - **Contenido**: BHR-v1 como parte de cost optimization roadmap

### Configuraci√≥n

#### 3. **CONFIG_PARAMETERS.md**
   - **Archivo**: [CONFIG_PARAMETERS.md](../../CONFIG_PARAMETERS.md)
   - **Secci√≥n**: "LLM & AI Services"
   - **Par√°metros**:
     * `human_recognition.telemetry_enabled` (bool, default false)
     * `human_recognition.telemetry_retention_days` (int, default 365)
     * `human_recognition.telemetry_anonymous` (bool, default true)
     * `human_recognition.confidence_threshold` (float, default 0.85)
     * `human_recognition.fallback_to_vision_llm` (bool, default true)

### C√≥digo (Futuro v2.5)

#### 4. **src/ml/human_recognition.rs** (NOT YET IMPLEMENTED)
   - **Planned path**: `src/ml/human_recognition.rs`
   - **Structs**:
     * `TelemetryEntry`
     * `BHRModel` (ONNX wrapper)
     * `HumanRecognitionEngine`
   - **Implementation**: ~600 lines (v2.5, 2026 Q3)

#### 5. **src/ml/bhr_inference.rs** (NOT YET IMPLEMENTED)
   - **Planned path**: `src/ml/bhr_inference.rs`
   - **Purpose**: ONNX model loading + inference
   - **Dependencies**: `onnxruntime` crate
   - **Implementation**: ~300 lines (v2.5)

---

## üîó Conceptos Relacionados

### Identidad & Reconocimiento

- **[[bqm-quantum-masks]]** - Sistema de identidad base que BHR mejora
  * BHR mejora LocalIdentity matching (Q-Soul derivation m√°s r√°pida)
  * Confidence threshold determina si usar BHR o Vision LLM

- **[[identity-consent-flow]]** - CONSENT-FIRST philosophy
  * Telemetry collection requires explicit opt-in
  * User can revoke telemetry anytime
  * Trained model is public (no privacy risk), but data collection is private

### Optimizaci√≥n & Costos

- **[[cost-optimization]]** (CROSS_REFERENCE) - Estrategia general de costos
  * BHR-v1 es pilar de cost reduction (98% savings)
  * Complementa caching, batching, analysis frequency
  * Target: $17/month ‚Üí $7-9/month (v2.5)

### LLM & Estrategias

- **[[llm-strategies]]** (CROSS_REFERENCE) - Uso de LLMs en Bit√°cora
  * Vision LLM (GPT-4o): General image analysis
  * BHR-v1: Specialized task (identity only)
  * Hybrid approach: Local-first + cloud fallback

### Plataforma & Performance

- **[[battery-aware-processing]]** - Mobile considerations
  * BHR-v1 inference: ~50ms (vs 2-3s cloud)
  * Lower battery impact (no network)
  * Offline capability

---

## üìà Evoluci√≥n

### Timeline

#### **2025-11-29 23:00** - Propuesta Original
- **Context**: Eduardo analiza cost model ($2 motor + $15 LLM)
- **Insight**: "Recolectar par√°metros LLM ‚Üí entrenar propio mini-LLM"
- **Decision**: Dise√±ar HumanRecognition mini-LLM strategy
- **Document**: 18.4 secci√≥n "Future Evolution"

#### **v1.0-v1.5** (2026 Q1-Q2) - Telemetry Collection
- **Goal**: Recolectar 100k+ telemetry entries
- **Implementation**: 
  * TelemetryEntry struct
  * Local storage (YAML)
  * Opt-in consent flow
  * CONFIG parameters
- **Output**: Telemetry dataset ready for training

#### **v2.5** (2026 Q3) - BHR-v1 Training & Deployment
- **Goal**: Train first mini-LLM + deploy
- **Implementation**:
  * Aggregate anonymized telemetry (Bit√°cora Corp)
  * Train BHR-v1 (~100M params)
  * Distribute ONNX model (100MB)
  * Integrate inference pipeline
- **Cost**: $50 one-time training
- **Performance**: 85% hit rate target

#### **v3.0** (2026 Q4) - Hybrid Optimization
- **Goal**: Fine-tune hybrid strategy
- **Improvements**:
  * Per-user fine-tuning (optional)
  * Confidence threshold tuning
  * Fallback optimization (reduce to 10%)
- **Target hit rate**: 90%+

#### **v4.0+** (2027+) - Multi-Modal
- **Goal**: Expand beyond faces
- **Features**:
  * Voice recognition (audio snippets)
  * Handwriting recognition (notes)
  * Behavioral patterns (typing, speech)
- **Vision**: Holistic identity recognition

---

## üé® Estado Actual

### Fase

- **Dise√±o**: ‚úÖ Complete (2025-11-29)
- **Telemetry Collection**: ‚è≥ Pending (v1.0-v2.0)
- **Training**: ‚è≥ Pending (v2.5)
- **Deployment**: ‚è≥ Pending (v2.5)

### Prioridad

- **v1.0-v2.0**: BAJA (telemetry passive, no urgency)
- **v2.5**: ALTA (critical cost optimization)
- **v3.0+**: MEDIA (optimization, not blocker)

### Owner

- **Propuesta**: Eduardo GJ
- **Dise√±o**: Eduardo + Claude
- **Implementaci√≥n**: TBD (v2.5 team)

### Blockers

- ‚úÖ None (design complete)
- ‚è≥ Need telemetry collection (v1.0-v2.0)
- ‚è≥ Need 100k+ entries for training (12-18 months)

---

## üí° Preguntas Frecuentes

### P1: ¬øPor qu√© el costo no es $0 si es local?

**R:** El costo de inferencia es $0 (100% local). El "$0.0001/match" es el costo **amortizado de entrenamiento**:

- Training cost: $50 one-time
- Expected lifetime: 500k matches
- Amortized: $50 / 500,000 = $0.0001 per match

Despu√©s de 5,000 matches (~3 meses), BHR-v1 se paga a s√≠ mismo vs GPT-4o.

### P2: ¬øQu√© pasa si BHR-v1 falla?

**R:** Hybrid fallback strategy:

```
1. Try BHR-v1 (local, $0)
   - Confidence > 0.85? ‚Üí Use result
   
2. Fallback to GPT-4o (cloud, $0.01)
   - Confidence < 0.85? ‚Üí Use Vision LLM
```

User never notices. Worst case: 15% matches use GPT-4o ($0.0015 average vs $0.01 pure cloud).

### P3: ¬øQu√© datos se env√≠an a Bit√°cora Corp?

**R:** NADA sin consentimiento expl√≠cito.

- Telemetry collection: **Opt-in** (default OFF)
- Data sent: **Anonymized** (hashed user IDs)
- Face embeddings: **Vectors only** (no raw images)
- Trained model: **Public** (no privacy risk)

User controls todo desde CONFIG_PARAMETERS.md.

### P4: ¬øFunciona offline?

**R:** S√≠ (despu√©s de model download):

- BHR-v1 model: 100MB one-time download
- Inference: 100% local (no network)
- Fallback: Requires internet (GPT-4o)

User puede desactivar fallback ‚Üí 100% offline con degraded accuracy.

### P5: ¬øQu√© tan preciso es vs GPT-4o?

**R:** Target (v2.5):

- **BHR-v1 alone**: 85% accuracy (specialized task)
- **GPT-4o**: 95% accuracy (general vision)
- **Hybrid (BHR + GPT fallback)**: 94% accuracy (best of both)

Trade-off: -1% accuracy for 98% cost savings.

---

## üìä M√©tricas de √âxito (v2.5)

### Telemetry Collection (v1.0-v2.0)

- ‚úÖ 100k+ telemetry entries collected
- ‚úÖ Opt-in rate: >30% users
- ‚úÖ Dataset quality: >90% valid entries

### Training (v2.5)

- ‚úÖ Model size: <150MB
- ‚úÖ Training cost: <$100
- ‚úÖ Inference latency: <100ms

### Deployment (v2.5+)

- ‚úÖ Hit rate: >85% (BHR-v1 alone)
- ‚úÖ Hybrid accuracy: >94%
- ‚úÖ Cost reduction: >95% vs GPT-4o
- ‚úÖ User satisfaction: >90% (no perceived degradation)

---

## üöÄ Next Steps

### Immediate (v1.0, Week 3-4)

1. ‚úÖ Design complete (this document)
2. ‚è≥ Create `TelemetryEntry` struct (Phase 7.x.3)
3. ‚è≥ Add CONFIG parameters
4. ‚è≥ Implement telemetry collection (opt-in flow)
5. ‚è≥ Local storage (YAML append)

### Short-term (v1.5-v2.0, Q1-Q2 2026)

6. ‚è≥ Monitor telemetry collection
7. ‚è≥ Analyze data quality
8. ‚è≥ Estimate training timeline (need 100k entries)

### Mid-term (v2.5, Q3 2026)

9. ‚è≥ Aggregate telemetry (Bit√°cora Corp)
10. ‚è≥ Train BHR-v1 (cloud GPUs)
11. ‚è≥ Distribute model (ONNX 100MB)
12. ‚è≥ Implement inference pipeline
13. ‚è≥ Test hybrid strategy
14. ‚è≥ Deploy to users

### Long-term (v3.0+, Q4 2026+)

15. ‚è≥ Optimize hit rate (>90%)
16. ‚è≥ Per-user fine-tuning
17. ‚è≥ Multi-modal expansion (voice, handwriting)

---

## üß© Integration Points

### Input Dependencies

- **ImageAnalyzer** (18.2): Face embeddings extraction
- **VisionLLMClient**: Fallback matching
- **ConversationContext**: Context for inference
- **ConsentTracker** (18.4): Telemetry opt-in

### Output Dependencies

- **IdentityManager** (18.4): Consumes IdentityMatch results
- **IdentityLinker** (18.4): Uses confidence scores
- **CONFIG_PARAMETERS**: User controls telemetry + thresholds

---

## üìö Referencias

### Documentos

- [18.4 BQM Identity System v1.0](../../ROADMAP_V2/02_COMPONENTES/18.4_bqm-identity-system-v1.md#future-evolution-humanrecognition-mini-llm)
- [18.5 BQM Quantum Vision v2.0](../../ROADMAP_V2/00_VISION/18.5_bqm-quantum-identity-vision-v2.md)
- [CONFIG_PARAMETERS.md](../../CONFIG_PARAMETERS.md#llm-ai-services)
- [CROSS_REFERENCES/cost-optimization.md](../CROSS_REFERENCES/cost-optimization.md)

### Papers & Tech

- FaceNet (face embeddings): [Schroff et al. 2015]
- Lightweight Transformers: [MobileViT, EfficientFormer]
- ONNX Runtime: [Microsoft ONNX docs]

### Decisiones

- **DA-TBD**: HumanRecognition Mini-LLM Architecture (pending formal approval)

---

**Tags**: `#ml` `#cost-optimization` `#local-inference` `#v2.5` `#eduardo-insight`  
**Decisi√≥n**: DA-TBD  
**√öltima Actualizaci√≥n**: 2025-11-29 23:52:00  
**Mantenedores**: Eduardo GJ + Claude  

üß†‚ú®üíé
