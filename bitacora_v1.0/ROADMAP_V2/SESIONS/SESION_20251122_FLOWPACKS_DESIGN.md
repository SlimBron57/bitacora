# üé® SESI√ìN DE DISE√ëO: FlowPacks Anti-Disco-Rayado

```yaml
Fecha: 2025-11-22
Componente: FlowPacks (Contextual Compression)
Fase: Phase 1 - Design (4 horas)
Referencia: FLOWPACKS_IMPLEMENTATION_PLAN.md (44KB)
Objetivo: Dise√±ar arquitectura completa ANTES de codificar
```

---

## üéØ PROBLEMA A RESOLVER

**S√≠ntoma:** "Disco rayado" - Bit√°cora repite mismas explicaciones sin detectar que el usuario ya pregunt√≥ antes.

**Causa ra√≠z:**
- FBCU comprime mensajes INDIVIDUALES (2-15x)
- NO hay detecci√≥n de similitud sem√°ntica entre conversaciones
- NO hay relaci√≥n entre mensajes de diferentes sesiones
- TelescopeDB almacena entries independientes

**Impacto:**
- üòû Usuario frustrado: "Ya te lo pregunt√© hace 2 d√≠as"
- üí∏ Tokens desperdiciados: 1000 palabras (2 explicaciones) vs 550 (1 + referencia)
- ü§ñ Sensaci√≥n de IA tonta: "No recuerda nada"

---

## üèóÔ∏è ARQUITECTURA DISE√ëADA

### M√≥dulos (7 archivos)

```
src/flowpacks/
‚îú‚îÄ‚îÄ mod.rs              # FlowPackEngine (orquestador principal)
‚îú‚îÄ‚îÄ flowpack.rs         # FlowPack, FlowPackEntry, EntryType
‚îú‚îÄ‚îÄ similarity.rs       # SimilarityIndex (embeddings + b√∫squeda)
‚îú‚îÄ‚îÄ response.rs         # AdaptiveResponse (Reference/PartialReference/Full)
‚îú‚îÄ‚îÄ compression.rs      # Estrategias de compresi√≥n contextual
‚îú‚îÄ‚îÄ config.rs           # FlowPackConfig (umbrales, par√°metros)
‚îî‚îÄ‚îÄ error.rs            # FlowPackError
```

### Flujo de Datos

```
Usuario: "¬øQu√© es CTX7D?"
    ‚Üì
[1] FlowPackEngine.compress_message()
    ‚îú‚îÄ> FBCU.compress() ‚Üí FBCUCore (15x ratio)
    ‚îú‚îÄ> SimilarityIndex.search_similar() ‚Üí Vec<SimilarMatch>
    ‚îÇ   ‚îú‚îÄ Genera embedding (MiniLM-L6-v2, 384 dims)
    ‚îÇ   ‚îî‚îÄ Busca en HNSW index (k=10, threshold=0.85)
    ‚îî‚îÄ> Decisi√≥n:
        ‚îú‚îÄ NO similar (< 0.85) ‚Üí Crear nuevo FlowPack (Base)
        ‚îî‚îÄ S√ç similar (‚â• 0.85) ‚Üí A√±adir a FlowPack existente
            ‚îú‚îÄ Muy similar (‚â• 0.95) ‚Üí EntryType::Reference
            ‚îî‚îÄ Similar (0.85-0.95) ‚Üí EntryType::Delta
    ‚Üì
[2] FlowPack almacenado en TelescopeDB
    ‚îú‚îÄ ID: "fp_session1_1732320000"
    ‚îú‚îÄ Entries: [entry_0 (Base), entry_1 (Reference), ...]
    ‚îú‚îÄ Centroid embedding: [0.23, -0.45, ..., 0.67]
    ‚îî‚îÄ Stats: compression_ratio = 25.3x
```

```
Usuario (2 d√≠as despu√©s): "Recu√©rdame CTX7D"
    ‚Üì
[3] FlowPackEngine.generate_adaptive_response()
    ‚îú‚îÄ> SimilarityIndex.search_similar()
    ‚îÇ   ‚îî‚îÄ> Encuentra FlowPack similar (similarity=0.96)
    ‚îú‚îÄ> Decisi√≥n basada en similarity:
    ‚îÇ   ‚îú‚îÄ > 0.95 ‚Üí AdaptiveResponse::Reference
    ‚îÇ   ‚îÇ   ‚îî‚îÄ> "Ya te expliqu√© esto el 2025-11-20..."
    ‚îÇ   ‚îú‚îÄ 0.85-0.95 ‚Üí AdaptiveResponse::PartialReference
    ‚îÇ   ‚îÇ   ‚îî‚îÄ> "Hablamos de esto antes, aqu√≠ lo nuevo..."
    ‚îÇ   ‚îî‚îÄ < 0.85 ‚Üí AdaptiveResponse::Full
    ‚îÇ       ‚îî‚îÄ> Explicaci√≥n completa desde cero
    ‚îî‚îÄ> Actualizar FlowPack (a√±adir referencia)
```

---

## üìê ESTRUCTURAS DE DATOS (Dise√±o)

### FlowPack (contenedor de mensajes relacionados)

```rust
pub struct FlowPack {
    /// ID √∫nico: "fp_{session_id}_{timestamp}"
    pub id: String,
    
    /// ID de sesi√≥n (agrupa conversaciones)
    pub session_id: String,
    
    /// Mensajes agrupados (comprimidos)
    pub entries: Vec<FlowPackEntry>,
    
    /// Embedding centroide (promedio de todos)
    /// Dimensi√≥n: 384 (MiniLM-L6-v2)
    pub centroid_embedding: Vec<f64>,
    
    /// Timestamps
    pub first_timestamp: DateTime<Utc>,
    pub last_timestamp: DateTime<Utc>,
    
    /// Estad√≠sticas
    pub stats: CompressionStats,
}
```

**Decisi√≥n de dise√±o:**
- ¬øPor qu√© centroid embedding? ‚Üí B√∫squeda r√°pida sin recalcular todos los entries
- ¬øActualizar centroid al a√±adir entry? ‚Üí S√ç, promedio incremental
- ¬øL√≠mite de entries? ‚Üí Config: max_pack_size (default: 20)

### FlowPackEntry (mensaje individual)

```rust
pub struct FlowPackEntry {
    /// ID √∫nico: "{pack_id}_{index}"
    pub id: String,
    
    /// FBCU Core (compresi√≥n individual 15x)
    pub fbcu_core: FBCUCore,
    
    /// Timestamp del mensaje
    pub timestamp: DateTime<Utc>,
    
    /// Tipo: Base, Reference, Delta
    pub entry_type: EntryType,
    
    /// Si es Reference/Delta: ID de la base
    pub reference_to: Option<String>,
    
    /// Snapshot del CTX7D (metadata)
    pub ctx7d_snapshot: ContextToken7D,
    
    /// Texto original (para an√°lisis)
    pub original_text: String,
}
```

**Decisi√≥n de dise√±o:**
- ¬øGuardar original_text? ‚Üí S√ç, para an√°lisis de diferencias (extract_differences)
- ¬øGuardar CTX7D completo? ‚Üí S√ç, para entender contexto emocional/temporal

### EntryType (clasificaci√≥n de entrada)

```rust
pub enum EntryType {
    /// Primera explicaci√≥n (completa)
    Base,
    
    /// Repetici√≥n exacta (>0.95 similitud)
    Reference {
        base_entry_id: String,
    },
    
    /// Similar pero con diferencias (0.85-0.95)
    Delta {
        base_entry_id: String,
        differences: Vec<String>, // Palabras nuevas
    },
}
```

**Decisi√≥n de dise√±o:**
- ¬øPor qu√© separar Reference y Delta? ‚Üí Compresi√≥n diferencial (Delta guarda solo diffs)
- ¬øC√≥mo calcular differences? ‚Üí Set difference de palabras (baseline: Jaccard)

### AdaptiveResponse (respuesta inteligente)

```rust
pub enum AdaptiveResponse {
    /// Usuario pregunta EXACTAMENTE lo mismo
    Reference {
        pack_id: String,
        original_date: DateTime<Utc>,
        summary: String,
        suggestion: String,
    },
    
    /// Usuario pregunta algo SIMILAR
    PartialReference {
        pack_id: String,
        differences: Vec<String>,
        new_aspects: Vec<String>,
    },
    
    /// Usuario pregunta algo NUEVO
    Full {
        requires_new_explanation: bool,
    },
}
```

**Decisi√≥n de dise√±o:**
- ¬øC√≥mo generar suggestion? ‚Üí Template: "¬øQuieres profundizar en [aspecto]?"
- ¬øDetectar new_aspects? ‚Üí NLP simple: palabras nuevas + clustering sem√°ntico

---

## üîç SIMILARITY INDEX (Dise√±o Detallado)

### Modelo de Embeddings

**Opci√≥n A: Modelo local (sentence-transformers)**
- Modelo: `all-MiniLM-L6-v2`
- Dimensi√≥n: 384
- Velocidad: ~100 sentences/sec (CPU)
- Ventaja: Local-first, sin API calls
- Desventaja: Requiere modelo descargado (~90MB)

**Opci√≥n B: API externa (OpenAI/Cohere)**
- Modelo: `text-embedding-ada-002` (OpenAI)
- Dimensi√≥n: 1536
- Velocidad: ~1000 sentences/sec (API)
- Ventaja: Mayor calidad
- Desventaja: Costo, dependencia externa

**DECISI√ìN: Opci√≥n A (MiniLM-L6-v2)**
- Raz√≥n: DA-001 (Local-First Architecture)
- Trade-off: Calidad 90% vs costo $0

### HNSW Index

**Par√°metros dise√±ados:**
```rust
HnswConfig {
    m: 16,                // Conexiones por nodo
    ef_construction: 200, // Calidad del √≠ndice
    ef_search: 50,        // Recall en b√∫squeda
    max_elements: 10000,  // M√°ximo FlowPacks
}
```

**Decisi√≥n de dise√±o:**
- ¬øPor qu√© HNSW y no FAISS? ‚Üí HNSW es Rust-native, FAISS necesita FFI
- ¬øRebuild index cada vez? ‚Üí NO, incremental add
- ¬øPersistencia del index? ‚Üí S√ç, serializar a disk (bincode)

---

## üéØ API P√öBLICA (Dise√±o)

### FlowPackEngine

```rust
impl FlowPackEngine {
    /// Constructor
    pub fn new(config: FlowPackConfig) -> Result<Self>;
    
    /// Comprimir mensaje con detecci√≥n de contexto
    pub async fn compress_message(
        &mut self,
        message: &str,
        ctx7d: &ContextToken7D,
        session_id: &str,
    ) -> Result<FlowPackEntry>;
    
    /// Generar respuesta adaptada
    pub async fn generate_adaptive_response(
        &self,
        query: &str,
        ctx7d: &ContextToken7D,
    ) -> Result<AdaptiveResponse>;
    
    /// Buscar FlowPacks similares
    pub async fn find_similar_packs(
        &self,
        query: &str,
        ctx7d: &ContextToken7D,
        threshold: f64,
    ) -> Result<Vec<SimilarMatch>>;
    
    /// Obtener FlowPack por ID
    pub fn get_flowpack(&self, id: &str) -> Option<&FlowPack>;
    
    /// Estad√≠sticas
    pub fn stats(&self) -> &EngineStats;
}
```

### SimilarityIndex

```rust
impl SimilarityIndex {
    /// Constructor (carga modelo embeddings)
    pub fn new(model_path: Option<PathBuf>) -> Result<Self>;
    
    /// Generar embedding
    pub async fn encode(&self, text: &str) -> Result<Vec<f64>>;
    
    /// Buscar similares (k-NN)
    pub async fn search_similar(
        &self,
        query: &str,
        ctx7d: &ContextToken7D,
        threshold: f64,
    ) -> Result<Vec<SimilarMatch>>;
    
    /// A√±adir FlowPack al √≠ndice
    pub fn add_to_index(&mut self, pack_id: String, embedding: Vec<f64>) -> Result<()>;
}
```

---

## ‚öôÔ∏è CONFIGURACI√ìN (Dise√±o)

```rust
pub struct FlowPackConfig {
    // Umbrales de similitud
    pub similarity_threshold: f64,    // 0.85 (85%)
    pub exact_threshold: f64,         // 0.95 (95%)
    
    // Ventana temporal
    pub temporal_window_hours: u64,   // 72h (3 d√≠as)
    
    // L√≠mites
    pub max_pack_size: usize,         // 20 mensajes
    pub cache_size: usize,            // 100 FlowPacks en RAM
    
    // Compresi√≥n
    pub aggressive_compression: bool, // true
    pub wavelet_level: u8,            // 6
    pub fractal_level: u8,            // 8
    
    // Embeddings
    pub embedding_model_path: Option<PathBuf>, // None = default MiniLM
    pub embedding_dimension: usize,   // 384
    
    // HNSW
    pub hnsw_k: usize,               // 10 (top-k results)
    pub hnsw_ef_construction: usize, // 200
    pub hnsw_ef_search: usize,       // 50
    pub hnsw_m: usize,               // 16
}
```

**Presets dise√±ados:**
- `FlowPackConfig::default()` ‚Üí Balance (85% threshold, 72h window)
- `FlowPackConfig::fast()` ‚Üí Velocidad (80% threshold, 48h window, HNSW reducido)
- `FlowPackConfig::high_quality()` ‚Üí Calidad (90% threshold, 168h window, HNSW aumentado)

---

## üß™ TESTS DISE√ëADOS

### Test 1: Detecci√≥n de repetici√≥n exacta

```rust
#[tokio::test]
async fn test_exact_repetition_detection() {
    let mut engine = FlowPackEngine::new(FlowPackConfig::default()).unwrap();
    let ctx7d = ContextToken7D::default();
    
    // Primera pregunta
    let msg1 = "¬øQu√© es CTX7D?";
    let entry1 = engine.compress_message(msg1, &ctx7d, "session_1").await.unwrap();
    assert!(matches!(entry1.entry_type, EntryType::Base));
    
    // Misma pregunta (debe detectar)
    let msg2 = "¬øQu√© es CTX7D?";
    let entry2 = engine.compress_message(msg2, &ctx7d, "session_1").await.unwrap();
    assert!(matches!(entry2.entry_type, EntryType::Reference { .. }));
    
    // Respuesta adaptada
    let response = engine.generate_adaptive_response(msg2, &ctx7d).await.unwrap();
    assert!(matches!(response, AdaptiveResponse::Reference { .. }));
}
```

### Test 2: Ratio de compresi√≥n >20x

```rust
#[tokio::test]
async fn test_compression_ratio() {
    let mut engine = FlowPackEngine::new(FlowPackConfig::default()).unwrap();
    
    // 10 mensajes similares
    for i in 0..10 {
        let msg = format!("Explicame CTX7D variaci√≥n {}", i);
        engine.compress_message(&msg, &ctx7d, "session_1").await.unwrap();
    }
    
    let pack = engine.get_flowpack("fp_session_1_*").unwrap();
    let ratio = pack.compression_ratio();
    assert!(ratio > 20.0, "Ratio: {} < 20x", ratio);
}
```

### Test 3: Latencia de b√∫squeda <50ms

```rust
#[tokio::test]
async fn test_search_latency() {
    let engine = /* ... engine con 100 FlowPacks ... */;
    
    let start = Instant::now();
    let _ = engine.find_similar_packs("CTX7D", &ctx7d, 0.85).await.unwrap();
    let duration = start.elapsed();
    
    assert!(duration.as_millis() < 50, "Latency: {:?} > 50ms", duration);
}
```

---

## üö® RIESGOS IDENTIFICADOS

### Riesgo 1: Modelo embeddings no disponible
**Mitigaci√≥n:** Fallback a embeddings simples (TF-IDF) si modelo no se carga

### Riesgo 2: HNSW index memory usage
**Mitigaci√≥n:** LRU cache con l√≠mite configurable, persistencia a disk

### Riesgo 3: Similitud falsa positiva
**Mitigaci√≥n:** Threshold ajustable, validaci√≥n manual inicial

### Riesgo 4: Performance en >1000 FlowPacks
**Mitigaci√≥n:** HNSW escala bien, tests de stress con 10k packs

---

## üìä M√âTRICAS DE √âXITO

### T√©cnicas
- Ratio compresi√≥n: >20x (objetivo: 20-50x)
- Latencia b√∫squeda: <50ms
- Detecci√≥n repetici√≥n: >95% accuracy
- Memoria cache: <100MB (100 FlowPacks)

### UX
- Tokens ahorrados: >50% en repeticiones
- Respuestas adaptadas: >80% cuando aplica
- Sensaci√≥n "recuerda bien": Feedback usuario positivo

---

## ‚úÖ DECISIONES DE DISE√ëO CLAVE

1. **Embeddings locales (MiniLM)** vs API externa
   - ‚úÖ Local (DA-001)
   
2. **HNSW index** vs FAISS
   - ‚úÖ HNSW (Rust-native, no FFI)
   
3. **Guardar original_text**
   - ‚úÖ S√ç (an√°lisis de diferencias)
   
4. **Centroid embedding**
   - ‚úÖ Promedio incremental (O(1) update)
   
5. **Threshold defaults**
   - ‚úÖ 0.85 similarity, 0.95 exact
   
6. **Temporal decay**
   - ‚úÖ Exp decay: e^(-hours/168)
   
7. **Integration con TelescopeDB**
   - ‚úÖ FlowPacks como BiographicalEntry especial

---

## üöÄ PR√ìXIMOS PASOS

**Phase 1 (Design) - COMPLETO ‚úÖ**
- [x] Arquitectura de m√≥dulos
- [x] Estructuras de datos
- [x] API p√∫blica
- [x] Tests dise√±ados
- [x] Riesgos identificados

**Phase 2 (Implementation) - SIGUIENTE:**
1. Implementar m√≥dulos b√°sicos (error.rs, config.rs)
2. Implementar estructuras (flowpack.rs)
3. Implementar similarity.rs (STUB primero)
4. Implementar mod.rs (FlowPackEngine)
5. Implementar response.rs

**Phase 3 (Validation) - DESPU√âS:**
1. Tests unitarios
2. Integration con FBCU
3. Integration con TelescopeDB
4. Performance benchmarks

---

**Estado:** ‚úÖ DISE√ëO COMPLETO  
**Duraci√≥n:** ~3 horas  
**Siguiente:** Phase 2 - Core Implementation  

---

*Generado: 2025-11-22*  
*Sistema Bit√°cora v1.0 - FlowPacks Anti-Disco-Rayado Design*
