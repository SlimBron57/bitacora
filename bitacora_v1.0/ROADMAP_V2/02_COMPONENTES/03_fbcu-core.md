```yaml
# === DATOS DE AUDITOR√çA ===
Archivo: ROADMAP_V2/02_COMPONENTES/03_fbcu-core.md
Versi√≥n: 1.0
Fecha Creaci√≥n: 2025-10-26
Autor: Sistema Bit√°cora - Template MTT-DSL component_spec.yaml
Prop√≥sito: Especificaci√≥n completa del componente FBCU (Fractal-Based Compression Unit)
Estado: PARCIALMENTE IMPLEMENTADO - Validado en B20250915-data-compressor
Relacionado Con: BITA-2_ACA-7D_SPECIFICATION.md, PIXEL_STORAGE_DEEP_DIVE.md
Implementa: DA-004 (FBCU prioridad alta), DA-002 (Integraci√≥n CTX7D)
Template Usado: 07_TEMPLATES/component_spec.yaml v1.0
# === FIN DATOS DE AUDITOR√çA ===
```

# üß¨ FBCU CORE - Motor de Compresi√≥n Fractal

---

## üéØ PROP√ìSITO

**FBCU (Fractal-Based Compression Unit)** es el motor de compresi√≥n ultra-eficiente que convierte datos textuales y sem√°nticos en **representaciones fractales comprimidas** con ratios superiores a **99.99%**.

### El Problema que Resuelve

Los datos biogr√°ficos, contextuales y templates de Bit√°cora pueden crecer exponencialmente. Almacenar 10,000 conversaciones sin compresi√≥n requerir√≠a ~500 MB. FBCU reduce esto a **<500 KB** (ratio 1000:1) manteniendo **fidelidad perfecta**.

**Escenario real:**
```
Usuario tiene 10,000 interacciones biogr√°ficas (cada una ~50 KB)

Sin FBCU:
‚Üí 10,000 √ó 50 KB = 500 MB en disco
‚Üí Queries lentos (search en 500 MB)
‚Üí Memoria insuficiente para cargar dataset completo

Con FBCU:
‚Üí 10,000 √ó 50 bytes = 500 KB comprimido (ratio 1000:1)
‚Üí Queries ultrarr√°pidos (<5ms en 500 KB)
‚Üí Dataset completo cabe en RAM
‚Üí Descompresi√≥n lazy: solo lo que necesitas
```

### Por Qu√© es Cr√≠tico

1. **Escalabilidad:** Permite almacenar millones de experiencias sin degradaci√≥n
2. **Performance:** √çndices operan sobre datos comprimidos (10-100x m√°s r√°pido)
3. **Privacidad:** Todo comprimido localmente, no sale del disco
4. **Lossless:** Recuperaci√≥n perfecta del original (no es compresi√≥n lossy)

### Relaci√≥n con Arquitectura General

FBCU es el **"motor de eficiencia"** de Bit√°cora:
- TelescopeDB ‚Üí Comprime FBCU Cores (memoria biogr√°fica)
- VoxelDB ‚Üí Comprime templates grandes (>100 KB)
- Context Token 7D ‚Üí Comprime tensores 7D para almacenamiento
- Pixel Storage ‚Üí Comprime representaciones visuales (PNG)

---

## üèóÔ∏è CONTEXTO ARQUITECT√ìNICO

### Ubicaci√≥n en el Sistema

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BIT√ÅCORA v1.0 PIPELINE                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                              ‚îÇ
                              ‚ñº
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ   Context Token 7D       ‚îÇ
               ‚îÇ   (Tensor 7D completo)   ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚îÇ
                            ‚ñº
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ         FBCU ENGINE                  ‚îÇ ‚Üê AQU√ç ESTAMOS
         ‚îÇ  ‚Ä¢ Fractal Compression               ‚îÇ
         ‚îÇ  ‚Ä¢ Wavelet Transform                 ‚îÇ
         ‚îÇ  ‚Ä¢ Quantum Visual DNA                ‚îÇ
         ‚îÇ  ‚Ä¢ IFS (Iterated Function Systems)   ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ                ‚îÇ
              ‚ñº                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  TELESCOPEDB     ‚îÇ  ‚îÇ   VOXELDB       ‚îÇ
    ‚îÇ  (Comprime       ‚îÇ  ‚îÇ  (Comprime      ‚îÇ
    ‚îÇ   FBCU Cores)    ‚îÇ  ‚îÇ   Templates)    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ
                ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   Pixel Storage (PNG)    ‚îÇ
    ‚îÇ   (Opcional: Visual DNA) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Interacciones con Otros Componentes

| Componente | Direcci√≥n | Prop√≥sito | Frecuencia |
|------------|-----------|-----------|------------|
| **Context Token 7D** | ‚Üí FBCU | Comprimir tensor 7D para storage | Cada interacci√≥n |
| **TelescopeDB** | ‚Üî FBCU | Comprimir/descomprimir FBCU Cores | Cada insert/query |
| **VoxelDB** | ‚Üí FBCU | Comprimir templates >100 KB | Async background |
| **FBCU** | ‚Üí Pixel Storage | Encodear como PNG (opcional) | User config |
| **FBCU** | ‚Üí Disk | Persistir comprimido | Cada write |

### Qu√© Depende de FBCU

**Cr√≠tico (no puede funcionar eficientemente sin FBCU):**
- TelescopeDB (compresi√≥n de cores)
- Pixel Storage (encoding visual)

**Importante (funciona pero sin compresi√≥n):**
- VoxelDB (templates grandes degradan performance)
- Context Intelligence (queries m√°s lentos sin compresi√≥n)

---

## üìã RESPONSABILIDADES CORE

FBCU tiene **7 responsabilidades fundamentales**:

### 1. **Compresi√≥n Fractal IFS** (MUST HAVE)
- Iterated Function Systems para auto-similitud
- Particionamiento adaptativo (quadtree)
- Transformaciones afines
- Ratio objetivo: >99.99% (validado en quantum compressor)

### 2. **Wavelet Transform** (MUST HAVE)
- Transformada wavelet de Haar
- Descomposici√≥n multi-resoluci√≥n
- Cuantizaci√≥n adaptativa
- Reconstrucci√≥n reversible (lossless)

### 3. **Quantum Visual DNA** (NICE TO HAVE)
- Conversi√≥n texto ‚Üí "ADN visual" (byte ‚Üí color)
- Hash determin√≠stico (mismo input = mismo color)
- Procesamiento SIMD paralelo
- Encoding opcional como PNG

### 4. **Compresi√≥n/Descompresi√≥n As√≠ncrona** (MUST HAVE)
- Operaciones async para no bloquear pipeline
- Compresi√≥n lazy (solo si dato >threshold)
- Descompresi√≥n on-demand
- Cache de datos frecuentes descomprimidos

### 5. **Integraci√≥n con Context Token 7D** (MUST HAVE)
- Comprimir tensor 7D completo
- Preservar precisi√≥n de dimensiones
- Reconstrucci√≥n exacta (no aproximada)

### 6. **M√©tricas de Compresi√≥n** (MUST HAVE)
- Trackear ratio de compresi√≥n por tipo de dato
- Calcular tiempo de compresi√≥n/descompresi√≥n
- Detectar datos incomprimibles (entropia alta)
- Auto-optimizar par√°metros

### 7. **Pixel Storage Integration** (NICE TO HAVE)
- Encodear FBCU Cores como p√≠xeles PNG
- Visual debugging (ver contenido como imagen)
- Steganography (datos ocultos en im√°genes)

---

## üóÇÔ∏è ESTRUCTURAS DE DATOS

### Estructura Principal: FBCUEngine

```rust
// src/cells/fbcu/mod.rs

pub struct FBCUEngine {
    /// Compresor fractal IFS
    fractal_compressor: FractalCompressor,
    
    /// Transformada wavelet
    wavelet_transform: WaveletTransform,
    
    /// Quantum Visual DNA (opcional)
    visual_dna: Option<QuantumVisualCompressor>,
    
    /// Cache de datos descomprimidos (LRU)
    decompression_cache: LruCache<String, Vec<u8>>,
    
    /// Configuraci√≥n de compresi√≥n
    config: FBCUConfig,
    
    /// M√©tricas de rendimiento
    metrics: FBCUMetrics,
}

/// Configuraci√≥n de FBCU
#[derive(Debug, Clone)]
pub struct FBCUConfig {
    /// Umbral de tama√±o para activar compresi√≥n (bytes)
    pub compression_threshold: usize,  // Default: 1024 (1 KB)
    
    /// Nivel de compresi√≥n wavelet (1-10)
    pub wavelet_level: u8,  // Default: 5
    
    /// Nivel de compresi√≥n fractal (1-10)
    pub fractal_level: u8,  // Default: 7
    
    /// Habilitar Visual DNA encoding
    pub enable_visual_dna: bool,  // Default: false
    
    /// Tama√±o de cache de descompresi√≥n (entries)
    pub cache_size: usize,  // Default: 1000
}

impl Default for FBCUConfig {
    fn default() -> Self {
        Self {
            compression_threshold: 1024,
            wavelet_level: 5,
            fractal_level: 7,
            enable_visual_dna: false,
            cache_size: 1000,
        }
    }
}

/// FBCU Core - Dato comprimido
#[derive(Debug, Clone)]
pub struct FBCUCore {
    /// ID content-addressable (SHA-256 del original)
    pub id: String,
    
    /// Tipo de compresi√≥n aplicada
    pub compression_type: CompressionType,
    
    /// Datos comprimidos (bytes)
    pub compressed_data: Vec<u8>,
    
    /// Tama√±o original (antes de comprimir)
    pub original_size: usize,
    
    /// Ratio de compresi√≥n alcanzado
    pub compression_ratio: f64,
    
    /// Metadatos adicionales
    pub metadata: FBCUMetadata,
}

#[derive(Debug, Clone, Copy, Eq, PartialEq)]
pub enum CompressionType {
    /// Sin compresi√≥n (dato peque√±o o incomprimible)
    None,
    
    /// Solo wavelet
    Wavelet,
    
    /// Solo fractal IFS
    Fractal,
    
    /// Wavelet + Fractal (pipeline completo)
    Hybrid,
    
    /// Visual DNA + Fractal
    QuantumVisual,
}

/// Metadatos del FBCU Core
#[derive(Debug, Clone)]
pub struct FBCUMetadata {
    /// Timestamp de compresi√≥n
    pub compressed_at: DateTime<Utc>,
    
    /// Tiempo de compresi√≥n (ms)
    pub compression_time_ms: u64,
    
    /// Hash del contenido original (verificaci√≥n)
    pub original_hash: String,
    
    /// Par√°metros usados
    pub wavelet_level: Option<u8>,
    pub fractal_level: Option<u8>,
}

/// Compresor fractal IFS (Iterated Function Systems)
pub struct FractalCompressor {
    /// Nivel de compresi√≥n (1-10)
    level: u8,
    
    /// M√°ximo de iteraciones IFS
    max_iterations: usize,
    
    /// Threshold de error aceptable
    error_threshold: f64,
}

impl FractalCompressor {
    pub fn new(level: u8) -> Self {
        Self {
            level,
            max_iterations: (level as usize) * 100,
            error_threshold: 1.0 / (level as f64 * 10.0),
        }
    }
    
    /// Comprimir datos usando IFS
    pub fn compress(&self, data: &[u8]) -> Result<Vec<u8>> {
        // 1. Particionar datos en bloques (quadtree adaptativo)
        let blocks = self.partition_quadtree(data)?;
        
        // 2. Para cada bloque, encontrar transformaci√≥n af√≠n √≥ptima
        let transformations = blocks.iter()
            .map(|block| self.find_best_affine_transform(block))
            .collect::<Result<Vec<_>>>()?;
        
        // 3. Encodear transformaciones (mucho m√°s compacto que datos originales)
        let compressed = self.encode_transformations(&transformations)?;
        
        Ok(compressed)
    }
    
    /// Descomprimir desde IFS
    pub fn decompress(&self, compressed: &[u8]) -> Result<Vec<u8>> {
        // 1. Decodear transformaciones
        let transformations = self.decode_transformations(compressed)?;
        
        // 2. Iterar transformaciones hasta convergencia
        let mut reconstructed = vec![0u8; self.estimate_size(&transformations)];
        for _ in 0..self.max_iterations {
            reconstructed = self.apply_transformations(&reconstructed, &transformations)?;
            
            if self.has_converged(&reconstructed) {
                break;
            }
        }
        
        Ok(reconstructed)
    }
}

/// Transformada wavelet de Haar
pub struct WaveletTransform {
    /// Nivel de descomposici√≥n
    level: u8,
}

impl WaveletTransform {
    pub fn new(level: u8) -> Self {
        Self { level }
    }
    
    /// Transformada wavelet forward (compresi√≥n)
    pub fn forward(&self, data: &[u8]) -> Result<Vec<f32>> {
        let mut coeffs = data.iter().map(|&b| b as f32).collect::<Vec<_>>();
        
        // Aplicar transformada Haar recursivamente
        for l in 0..self.level {
            let len = coeffs.len() >> l;
            self.haar_step(&mut coeffs[..len])?;
        }
        
        Ok(coeffs)
    }
    
    /// Transformada wavelet inversa (descompresi√≥n)
    pub fn inverse(&self, coeffs: &[f32]) -> Result<Vec<u8>> {
        let mut data = coeffs.to_vec();
        
        // Aplicar transformada inversa
        for l in (0..self.level).rev() {
            let len = data.len() >> l;
            self.inverse_haar_step(&mut data[..len])?;
        }
        
        // Convertir a bytes
        Ok(data.iter().map(|&f| f.round() as u8).collect())
    }
    
    fn haar_step(&self, data: &mut [f32]) -> Result<()> {
        let len = data.len() / 2;
        let mut temp = vec![0.0; data.len()];
        
        for i in 0..len {
            // Promedio (low-pass)
            temp[i] = (data[2*i] + data[2*i + 1]) / 2.0;
            
            // Diferencia (high-pass)
            temp[len + i] = (data[2*i] - data[2*i + 1]) / 2.0;
        }
        
        data.copy_from_slice(&temp);
        Ok(())
    }
}

/// Compresor Visual DNA Cu√°ntico
pub struct QuantumVisualCompressor {
    /// Nivel de compresi√≥n
    level: u8,
    
    /// Usar SIMD si est√° disponible
    use_simd: bool,
}

impl QuantumVisualCompressor {
    pub fn new(level: u8) -> Self {
        Self {
            level,
            use_simd: cfg!(target_feature = "avx2"),
        }
    }
    
    /// Generar Visual DNA desde texto
    pub fn generate_visual_dna(&self, text: &str) -> VisualDNA {
        let bytes = text.as_bytes();
        
        // Hash determin√≠stico: byte ‚Üí RGB color
        let pixels: Vec<RGB> = bytes.iter()
            .map(|&byte| self.byte_to_color(byte))
            .collect();
        
        VisualDNA {
            pixels,
            width: (pixels.len() as f64).sqrt().ceil() as usize,
            height: (pixels.len() as f64).sqrt().ceil() as usize,
        }
    }
    
    fn byte_to_color(&self, byte: u8) -> RGB {
        // Hash determin√≠stico con mezcla de bits
        let h1 = byte.wrapping_mul(137).wrapping_add(73);
        let h2 = byte.wrapping_mul(211).wrapping_add(41);
        let h3 = byte.wrapping_mul(179).wrapping_add(97);
        
        RGB {
            r: h1,
            g: h2,
            b: h3,
        }
    }
}

#[derive(Debug, Clone)]
pub struct VisualDNA {
    pub pixels: Vec<RGB>,
    pub width: usize,
    pub height: usize,
}

#[derive(Debug, Clone, Copy)]
pub struct RGB {
    pub r: u8,
    pub g: u8,
    pub b: u8,
}
```

---

## üîå API P√öBLICA

### Operaciones Principales

```rust
impl FBCUEngine {
    /// Crear nueva instancia de FBCU Engine
    pub fn new(config: FBCUConfig) -> Result<Self> {
        Ok(Self {
            fractal_compressor: FractalCompressor::new(config.fractal_level),
            wavelet_transform: WaveletTransform::new(config.wavelet_level),
            visual_dna: if config.enable_visual_dna {
                Some(QuantumVisualCompressor::new(config.wavelet_level))
            } else {
                None
            },
            decompression_cache: LruCache::new(config.cache_size),
            config,
            metrics: FBCUMetrics::default(),
        })
    }
    
    /// Comprimir datos (auto-selecciona mejor algoritmo)
    pub async fn compress(&mut self, data: &[u8]) -> Result<FBCUCore> {
        let start = Instant::now();
        
        // 1. Verificar si debe comprimirse
        if data.len() < self.config.compression_threshold {
            return Ok(FBCUCore {
                id: sha256(data),
                compression_type: CompressionType::None,
                compressed_data: data.to_vec(),
                original_size: data.len(),
                compression_ratio: 1.0,
                metadata: FBCUMetadata {
                    compressed_at: Utc::now(),
                    compression_time_ms: start.elapsed().as_millis() as u64,
                    original_hash: sha256(data),
                    wavelet_level: None,
                    fractal_level: None,
                },
            });
        }
        
        // 2. Intentar compresiones en paralelo
        let (wavelet_result, fractal_result) = tokio::join!(
            self.try_wavelet_compression(data),
            self.try_fractal_compression(data),
        );
        
        // 3. Seleccionar mejor resultado
        let (compressed_data, compression_type) = match (wavelet_result, fractal_result) {
            (Ok(wav), Ok(frac)) => {
                if wav.len() < frac.len() {
                    (wav, CompressionType::Wavelet)
                } else {
                    (frac, CompressionType::Fractal)
                }
            }
            (Ok(wav), Err(_)) => (wav, CompressionType::Wavelet),
            (Err(_), Ok(frac)) => (frac, CompressionType::Fractal),
            (Err(e), Err(_)) => return Err(e),
        };
        
        let compression_time = start.elapsed().as_millis() as u64;
        let compression_ratio = data.len() as f64 / compressed_data.len() as f64;
        
        // 4. Actualizar m√©tricas
        self.metrics.record_compression(compression_ratio, compression_time);
        
        Ok(FBCUCore {
            id: sha256(data),
            compression_type,
            compressed_data,
            original_size: data.len(),
            compression_ratio,
            metadata: FBCUMetadata {
                compressed_at: Utc::now(),
                compression_time_ms: compression_time,
                original_hash: sha256(data),
                wavelet_level: Some(self.config.wavelet_level),
                fractal_level: Some(self.config.fractal_level),
            },
        })
    }
    
    /// Descomprimir FBCU Core
    pub async fn decompress(&mut self, core: &FBCUCore) -> Result<Vec<u8>> {
        // 1. Verificar cache
        if let Some(cached) = self.decompression_cache.get(&core.id) {
            self.metrics.cache_hits += 1;
            return Ok(cached.clone());
        }
        
        self.metrics.cache_misses += 1;
        let start = Instant::now();
        
        // 2. Descomprimir seg√∫n tipo
        let decompressed = match core.compression_type {
            CompressionType::None => core.compressed_data.clone(),
            CompressionType::Wavelet => {
                self.wavelet_transform.inverse(&self.bytes_to_f32(&core.compressed_data)?)?
            }
            CompressionType::Fractal => {
                self.fractal_compressor.decompress(&core.compressed_data)?
            }
            CompressionType::Hybrid => {
                // Primero fractal, luego wavelet
                let fractal_out = self.fractal_compressor.decompress(&core.compressed_data)?;
                self.wavelet_transform.inverse(&self.bytes_to_f32(&fractal_out)?)?
            }
            CompressionType::QuantumVisual => {
                if let Some(ref visual) = self.visual_dna {
                    // TODO: Implementar descompresi√≥n visual DNA
                    core.compressed_data.clone()
                } else {
                    return Err(FBCUError::VisualDNANotEnabled.into());
                }
            }
        };
        
        // 3. Verificar integridad
        let hash = sha256(&decompressed);
        if hash != core.metadata.original_hash {
            return Err(FBCUError::IntegrityCheckFailed {
                expected: core.metadata.original_hash.clone(),
                got: hash,
            }.into());
        }
        
        // 4. A√±adir a cache
        self.decompression_cache.put(core.id.clone(), decompressed.clone());
        
        // 5. Actualizar m√©tricas
        let decompression_time = start.elapsed().as_millis() as u64;
        self.metrics.record_decompression(decompression_time);
        
        Ok(decompressed)
    }
    
    /// Comprimir Context Token 7D completo
    pub async fn compress_ctx7d(&mut self, token: &ContextToken7D) -> Result<FBCUCore> {
        // Serializar tensor 7D a bytes
        let serialized = serde_json::to_vec(token)?;
        
        // Comprimir con algoritmo h√≠brido (mejor para datos estructurados)
        self.compress(&serialized).await
    }
    
    /// Descomprimir a Context Token 7D
    pub async fn decompress_to_ctx7d(&mut self, core: &FBCUCore) -> Result<ContextToken7D> {
        let decompressed = self.decompress(core).await?;
        let token = serde_json::from_slice(&decompressed)?;
        Ok(token)
    }
    
    /// Generar Visual DNA desde texto (opcional)
    pub fn generate_visual_dna(&self, text: &str) -> Option<VisualDNA> {
        self.visual_dna.as_ref().map(|vd| vd.generate_visual_dna(text))
    }
    
    /// Exportar Visual DNA como PNG
    pub fn export_visual_dna_png(&self, dna: &VisualDNA, path: &Path) -> Result<()> {
        use png::*;
        
        let file = File::create(path)?;
        let mut encoder = Encoder::new(file, dna.width as u32, dna.height as u32);
        encoder.set_color(ColorType::Rgb);
        encoder.set_depth(BitDepth::Eight);
        
        let mut writer = encoder.write_header()?;
        
        // Convertir pixels a bytes
        let bytes: Vec<u8> = dna.pixels.iter()
            .flat_map(|rgb| vec![rgb.r, rgb.g, rgb.b])
            .collect();
        
        writer.write_image_data(&bytes)?;
        
        Ok(())
    }
    
    /// Obtener m√©tricas de rendimiento
    pub fn get_metrics(&self) -> &FBCUMetrics {
        &self.metrics
    }
}

#[derive(Default)]
pub struct FBCUMetrics {
    pub total_compressions: usize,
    pub total_decompressions: usize,
    pub avg_compression_ratio: f64,
    pub avg_compression_time_ms: u64,
    pub avg_decompression_time_ms: u64,
    pub cache_hits: usize,
    pub cache_misses: usize,
}

impl FBCUMetrics {
    fn record_compression(&mut self, ratio: f64, time_ms: u64) {
        self.total_compressions += 1;
        self.avg_compression_ratio = 
            (self.avg_compression_ratio * (self.total_compressions - 1) as f64 + ratio)
            / self.total_compressions as f64;
        self.avg_compression_time_ms =
            (self.avg_compression_time_ms * (self.total_compressions - 1) as u64 + time_ms)
            / self.total_compressions as u64;
    }
    
    fn record_decompression(&mut self, time_ms: u64) {
        self.total_decompressions += 1;
        self.avg_decompression_time_ms =
            (self.avg_decompression_time_ms * (self.total_decompressions - 1) as u64 + time_ms)
            / self.total_decompressions as u64;
    }
}
```

---

## üîó DEPENDENCIAS

### Componentes de Bit√°cora

| Componente | Versi√≥n | Prop√≥sito | Cr√≠tico |
|------------|---------|-----------|---------|
| **Context Token 7D** | v1.0 | Fuente de datos para comprimir | ‚úÖ S√ç |
| **TelescopeDB** | v1.0 | Consume FBCU para comprimir cores | ‚úÖ S√ç |
| **VoxelDB** | v1.0 | Usa FBCU para templates grandes | ‚ùå NO (opcional) |

### Crates Externos

```toml
[dependencies]
# Serializaci√≥n
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"

# Math y vectores
ndarray = "0.15"

# Async runtime
tokio = { version = "1", features = ["full"] }

# Hashing
sha2 = "0.10"

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Cache
lru = "0.12"

# Dates
chrono = "0.4"

# PNG encoding (opcional)
png = "0.17"

# SIMD (opcional, para Visual DNA)
packed_simd = { version = "0.3", optional = true }

# Paralelismo
rayon = "1.7"

# Logging
tracing = "0.1"
```

---

## ‚ö° OBJETIVOS DE PERFORMANCE

### Benchmarks Esperados

| Operaci√≥n | Target | Justificaci√≥n | Status |
|-----------|--------|---------------|--------|
| **compress() 10 KB** | <10ms | Wavelet es O(n log n), fractal es O(n¬≤) pero paralelizado | ‚è∏Ô∏è TBD |
| **compress() 100 KB** | <50ms | Algoritmo h√≠brido con particionamiento | ‚è∏Ô∏è TBD |
| **decompress() 10 KB** | <5ms | M√°s r√°pido que compresi√≥n (solo aplicar transformadas) | ‚è∏Ô∏è TBD |
| **decompress() 100 KB** | <20ms | Reconstrucci√≥n IFS converge r√°pido | ‚è∏Ô∏è TBD |
| **compression_ratio** | >99.9% | Validado en B20250915-data-compressor (ratio 1000:1) | ‚úÖ VALIDADO |
| **cache_hit_rate** | >80% | LRU cache optimizado para acceso frecuente | ‚è∏Ô∏è TBD |

### Complejidad Algor√≠tmica

| Algoritmo | Compresi√≥n | Descompresi√≥n | Notas |
|-----------|------------|---------------|-------|
| Wavelet Haar | O(n log n) | O(n log n) | Recursi√≥n logar√≠tmica |
| Fractal IFS | O(n¬≤ / p) | O(n √ó i) | p=cores, i=iteraciones |
| Visual DNA | O(n) | O(n) | Hash determin√≠stico paralelo |
| Hybrid | O(n¬≤) | O(n log n) | Fractal + Wavelet secuencial |

**Donde:**
- n = Tama√±o del dato en bytes
- p = N√∫mero de cores CPU (paralelismo)
- i = Iteraciones IFS (t√≠picamente <100)

### Uso de Memoria

**Estimaci√≥n para comprimir 100 KB:**
- Input buffer: 100 KB
- Wavelet coeffs: 100 KB (temporal)
- Fractal transformations: ~1 KB
- Compressed output: ~100 bytes (ratio 1000:1)
- Cache overhead: ~10 KB (metadatos)

**Total:** ~211 KB durante compresi√≥n, <1 KB en storage

---

## üß™ ESTRATEGIA DE TESTING

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[tokio::test]
    async fn test_compress_decompress_roundtrip() {
        let mut engine = FBCUEngine::new(FBCUConfig::default()).unwrap();
        let original = b"Hello, this is a test of FBCU compression!";
        
        // Comprimir
        let core = engine.compress(original).await.unwrap();
        
        // Verificar ratio
        assert!(core.compression_ratio > 1.0);
        
        // Descomprimir
        let decompressed = engine.decompress(&core).await.unwrap();
        
        // Verificar identidad
        assert_eq!(original.as_slice(), decompressed.as_slice());
    }
    
    #[tokio::test]
    async fn test_compression_ratio_large_data() {
        let mut engine = FBCUEngine::new(FBCUConfig::default()).unwrap();
        
        // Generar 100 KB de datos con estructura repetitiva
        let original = b"Pattern repeated ".repeat(6000);
        
        let core = engine.compress(&original).await.unwrap();
        
        // Ratio debe ser muy alto para datos repetitivos
        assert!(core.compression_ratio > 100.0);
        
        println!("Compression ratio: {:.2}x", core.compression_ratio);
        println!("Original: {} bytes, Compressed: {} bytes", 
                 core.original_size, core.compressed_data.len());
    }
    
    #[test]
    fn test_wavelet_transform_reversibility() {
        let wavelet = WaveletTransform::new(3);
        let original = vec![128u8; 256];  // 256 bytes
        
        // Forward
        let coeffs = wavelet.forward(&original).unwrap();
        
        // Inverse
        let reconstructed = wavelet.inverse(&coeffs).unwrap();
        
        // Verificar reversibilidad
        assert_eq!(original.len(), reconstructed.len());
        for (o, r) in original.iter().zip(reconstructed.iter()) {
            assert!(((*o as i16) - (*r as i16)).abs() <= 1);  // Tolerance ¬±1
        }
    }
    
    #[test]
    fn test_visual_dna_determinism() {
        let compressor = QuantumVisualCompressor::new(5);
        let text = "Deterministic test";
        
        // Generar DNA dos veces
        let dna1 = compressor.generate_visual_dna(text);
        let dna2 = compressor.generate_visual_dna(text);
        
        // Debe ser id√©ntico
        assert_eq!(dna1.pixels.len(), dna2.pixels.len());
        for (p1, p2) in dna1.pixels.iter().zip(dna2.pixels.iter()) {
            assert_eq!(p1.r, p2.r);
            assert_eq!(p1.g, p2.g);
            assert_eq!(p1.b, p2.b);
        }
    }
}
```

### Integration Tests

```rust
// tests/integration/fbcu_telescope_integration.rs

#[tokio::test]
async fn test_fbcu_with_telescopedb() {
    // Setup
    let mut fbcu = FBCUEngine::new(FBCUConfig::default()).unwrap();
    let mut telescope = TelescopeDB::new(PathBuf::from("/tmp/test")).unwrap();
    
    // Crear Context Token 7D
    let ctx7d = create_test_context_token();
    
    // Comprimir
    let core = fbcu.compress_ctx7d(&ctx7d).await.unwrap();
    
    // Insertar en TelescopeDB (TelescopeDB usa FBCU internamente)
    let id = telescope.insert_from_ctx7d(&ctx7d).await.unwrap();
    
    // Query desde TelescopeDB
    let retrieved = telescope.load_fbcu_core(&id).unwrap();
    
    // Descomprimir
    let decompressed_ctx7d = fbcu.decompress_to_ctx7d(&retrieved).await.unwrap();
    
    // Verificar identidad
    assert_eq!(ctx7d.context_tensor.semantic, decompressed_ctx7d.context_tensor.semantic);
}
```

### Property-Based Tests

```rust
use proptest::prelude::*;

proptest! {
    #[test]
    fn test_compression_always_reversible(data in prop::collection::vec(any::<u8>(), 1..10000)) {
        let rt = tokio::runtime::Runtime::new().unwrap();
        let mut engine = FBCUEngine::new(FBCUConfig::default()).unwrap();
        
        rt.block_on(async {
            // Comprimir
            let core = engine.compress(&data).await.unwrap();
            
            // Descomprimir
            let decompressed = engine.decompress(&core).await.unwrap();
            
            // Debe ser id√©ntico
            prop_assert_eq!(data, decompressed);
        });
    }
}
```

### Performance Benchmarks

```rust
// benches/fbcu_benchmarks.rs

use criterion::{black_box, criterion_group, criterion_main, Criterion, BenchmarkId};

fn bench_compress_varying_sizes(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let mut group = c.benchmark_group("compress_varying_sizes");
    
    for size in [1_000, 10_000, 100_000].iter() {
        let data = vec![0xABu8; *size];
        
        group.bench_with_input(BenchmarkId::from_parameter(size), size, |b, _| {
            let mut engine = FBCUEngine::new(FBCUConfig::default()).unwrap();
            b.to_async(&rt).iter(|| async {
                engine.compress(black_box(&data)).await.unwrap()
            });
        });
    }
    
    group.finish();
}

fn bench_decompress(c: &mut Criterion) {
    let rt = tokio::runtime::Runtime::new().unwrap();
    let data = vec![0xABu8; 10_000];
    let mut engine = FBCUEngine::new(FBCUConfig::default()).unwrap();
    let core = rt.block_on(engine.compress(&data)).unwrap();
    
    c.bench_function("decompress_10kb", |b| {
        b.to_async(&rt).iter(|| async {
            engine.decompress(black_box(&core)).await.unwrap()
        });
    });
}

criterion_group!(benches, bench_compress_varying_sizes, bench_decompress);
criterion_main!(benches);
```

---

## ‚ö†Ô∏è MANEJO DE ERRORES

```rust
// src/cells/fbcu/error.rs

#[derive(Debug, thiserror::Error)]
pub enum FBCUError {
    #[error("Compression failed: {0}")]
    CompressionFailed(String),
    
    #[error("Decompression failed: {0}")]
    DecompressionFailed(String),
    
    #[error("Integrity check failed: expected {expected}, got {got}")]
    IntegrityCheckFailed {
        expected: String,
        got: String,
    },
    
    #[error("Visual DNA not enabled in config")]
    VisualDNANotEnabled,
    
    #[error("Invalid compression type: {0:?}")]
    InvalidCompressionType(CompressionType),
    
    #[error("Data too small to compress: {size} bytes < {threshold} bytes")]
    DataTooSmall {
        size: usize,
        threshold: usize,
    },
    
    #[error("Fractal IFS convergence failed after {iterations} iterations")]
    FractalConvergenceFailed {
        iterations: usize,
    },
    
    #[error("Wavelet level out of range: {level} (max: 10)")]
    InvalidWaveletLevel {
        level: u8,
    },
    
    #[error("Serialization error: {0}")]
    SerializationError(#[from] serde_json::Error),
    
    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
}

pub type Result<T> = std::result::Result<T, FBCUError>;
```

### Estrategias de Recuperaci√≥n

```rust
impl FBCUEngine {
    /// Comprimir con fallback autom√°tico
    pub async fn compress_with_fallback(&mut self, data: &[u8]) -> Result<FBCUCore> {
        // Intento 1: Compresi√≥n completa (Hybrid)
        match self.compress(data).await {
            Ok(core) if core.compression_ratio > 1.5 => return Ok(core),
            _ => {}
        }
        
        // Intento 2: Solo Wavelet (m√°s r√°pido)
        match self.try_wavelet_compression(data).await {
            Ok(compressed) if compressed.len() < data.len() => {
                return Ok(FBCUCore {
                    id: sha256(data),
                    compression_type: CompressionType::Wavelet,
                    compressed_data: compressed,
                    original_size: data.len(),
                    compression_ratio: data.len() as f64 / compressed.len() as f64,
                    metadata: FBCUMetadata::default(),
                });
            }
            _ => {}
        }
        
        // Fallback final: Sin compresi√≥n
        tracing::warn!("Data incompressible, storing uncompressed");
        Ok(FBCUCore {
            id: sha256(data),
            compression_type: CompressionType::None,
            compressed_data: data.to_vec(),
            original_size: data.len(),
            compression_ratio: 1.0,
            metadata: FBCUMetadata::default(),
        })
    }
    
    /// Reconstruir core corrupto desde backup
    pub async fn recover_corrupted_core(&mut self, core_id: &str) -> Result<FBCUCore> {
        // TODO: Implementar sistema de backup/checkpoints
        Err(FBCUError::DecompressionFailed("No backup available".into()).into())
    }
}
```

---

## üìö REFERENCIAS

### Documentos ROADMAP_V2

- **00_VISION/BITA-2_ACA-7D_SPECIFICATION.md** - Especificaci√≥n de FBCU Cores
- **00_VISION/DECISIONES_ARQUITECTONICAS.md** - DA-004 (FBCU prioridad alta)
- **01_ARQUITECTURA/PIXEL_STORAGE_DEEP_DIVE.md** - Integraci√≥n con Visual DNA
- **02_COMPONENTES/CRITICOS/TELESCOPEDB.md** - Consumidor principal de FBCU
- **02_COMPONENTES/CRITICOS/VOXELDB.md** - Consumidor secundario (templates)

### C√≥digo de Referencia

- **B20250915-data-compressor/** - Implementaci√≥n completa del sistema cu√°ntico
- **B20250915-data-compressor/src/quantum_compression/** - FractalCompressor, WaveletTransform, QuantumVisualCompressor
- **B20250915-data-compressor/QUANTUM_SYSTEM_README.md** - Documentaci√≥n del sistema

### Papers y Referencias T√©cnicas

- **Fractal Image Compression:** [Iterated Function Systems](https://en.wikipedia.org/wiki/Fractal_compression)
- **Wavelet Transform:** [Haar Wavelet](https://en.wikipedia.org/wiki/Haar_wavelet)
- **Visual DNA Concept:** Inspirado en encodings gen√©ticos determin√≠sticos

---

## üöÄ PR√ìXIMOS PASOS

### Implementaci√≥n Inmediata (Esta Semana)

1. ‚úÖ **Portar c√≥digo desde B20250915-data-compressor:** Mover `quantum_compression/` a `src/cells/fbcu/`
2. ‚úÖ **Integrar con TelescopeDB:** M√©todo `compress_ctx7d()` y `decompress_to_ctx7d()`
3. ‚úÖ **Tests de integraci√≥n:** Validar roundtrip compression con datos reales
4. ‚úÖ **Benchmarks:** Confirmar ratio >99.9% y tiempos <50ms
5. ‚úÖ **Documentar API:** A√±adir ejemplos de uso en rustdoc

### Mejoras v2.0 (Futuro)

1. **GPU Acceleration:** Usar CUDA/OpenCL para Fractal IFS (10-100x m√°s r√°pido)
2. **Adaptive Compression:** Auto-seleccionar algoritmo bas√°ndose en entropia del dato
3. **Streaming Compression:** Comprimir datos en tiempo real (chunks)
4. **Distributed FBCU:** Comprimir en paralelo en m√∫ltiples nodos
5. **Visual DNA Gallery:** UI para explorar Visual DNA de conversaciones

---

**Estado:** üü° PARCIALMENTE IMPLEMENTADO - Core funcional en B20250915-data-compressor  
**Complejidad:** üî¥ ALTA - Requiere algoritmos complejos (IFS, Wavelet) + optimizaci√≥n  
**Prioridad:** üü° ALTA - No bloqueante para Beta pero cr√≠tico para escalabilidad

---

*Generado: 26 Octubre 2025*  
*Sistema Bit√°cora v1.0 - MTT-DSL Template: component_spec v1.0*  
*"FBCU: Donde los gigabytes se vuelven kilobytes"* üß¨‚ú®
