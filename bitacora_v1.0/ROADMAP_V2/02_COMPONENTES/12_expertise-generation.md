```yaml
# === DATOS DE AUDITOR√çA ===
Archivo: ROADMAP_V2/02_COMPONENTES/12_expertise-generation.md
Versi√≥n: 1.0.0
Fecha Creaci√≥n: 2025-10-26
Autor: Sistema Bit√°cora - Documentaci√≥n MTT-DSL
Prop√≥sito: Especificaci√≥n componente Expertise Generation (Generaci√≥n autom√°tica de conocimiento experto)
Estado: üìã ESPECIFICACI√ìN
Relacionado Con:
  - ROADMAP_V2/02_COMPONENTES/CRITICOS/TELESCOPEDB.md
  - ROADMAP_V2/02_COMPONENTES/IMPORTANTES/MTT_DSL_TEMPLATES.md
  - ROADMAP_V2/02_COMPONENTES/CRITICOS/CONTEXT_TOKEN_7D.md
  - src/expertise_generation/ (C√≥digo base existente)
Implementa:
  - DA-027: Expertise Generation desde TelescopeDB (Patrones biogr√°ficos)
  - DA-010: Cavalry Rush System (Multi-agent expertise generation)
  - BITA-2: ACA-7D Biographical Dimension Analysis
# === FIN DATOS DE AUDITOR√çA ===
```

# üéì EXPERTISE GENERATION - Generaci√≥n Autom√°tica de Conocimiento Experto

---

## üéØ PROP√ìSITO

El **sistema de Expertise Generation** es el componente de Bit√°cora responsable de **generar conocimiento experto especializado** para cualquier dominio mediante an√°lisis de patrones biogr√°ficos del usuario + despliegue de agentes especializados multi-LLM (Cavalry Rush).

### El Problema que Resuelve

**Escenario sin Expertise Generation:**
```
Usuario: "Quiero aprender machine learning"

Sistema b√°sico:
- Busca en Google "machine learning tutorial"
- Encuentra 10,000 recursos gen√©ricos
- Usuario confundido: ¬øPor d√≥nde empiezo?
- NO considera nivel actual del usuario
- NO personaliza ruta de aprendizaje
- NO adapta a biograf√≠a del usuario

Resultado:
‚ùå Usuario abrumado con informaci√≥n gen√©rica
‚ùå Abandona en el 80% de los casos (an√°lisis real)
‚ùå NO hay progresi√≥n estructurada
‚ùå Desperdicia tiempo en contenido irrelevante
```

**Con Expertise Generation (an√°lisis biogr√°fico + Cavalry Rush):**
```
Usuario: "Quiero aprender machine learning"
    ‚Üì
PASO 1: Analizar TelescopeDB (Biograf√≠a del usuario)
  Historial detectado:
  ‚îú‚îÄ 250 queries sobre Python (nivel: Advanced)
  ‚îú‚îÄ 45 queries sobre matem√°ticas (nivel: Intermediate)
  ‚îú‚îÄ 12 queries sobre estad√≠stica (nivel: Novice)
  ‚îî‚îÄ Patr√≥n: Usuario es dev backend senior, d√©bil en stats
    ‚Üì
PASO 2: Cavalry Rush (Desplegar 3 agentes especializados)
  üê¥ Agent #1 (OpenAI GPT-4): Analizar fundamentos ML
  üê¥ Agent #2 (Anthropic Claude): Dise√±ar curriculum progresivo
  üê¥ Agent #3 (Perplexity): Buscar recursos high-quality 2024
    ‚Üì
PASO 3: Generaci√≥n de Expertise Package
  üì¶ EXPERTISE: Machine Learning para Dev Backend
  
  ‚úÖ Nivel detectado: Intermediate (Python) + Novice (Stats)
  
  ‚úÖ Curriculum personalizado (6 fases):
      Fase 1: Stats refresher (2 semanas) ‚Üê ¬°Empieza aqu√≠!
      Fase 2: Numpy/Pandas advanced (1 semana)
      Fase 3: Supervised learning (3 semanas)
      Fase 4: Neural networks basics (4 semanas)
      Fase 5: Deep learning frameworks (6 semanas)
      Fase 6: Production ML systems (8 semanas)
  
  ‚úÖ Templates MTT-DSL generados (18):
      - ml_debugging_deep_dive.yaml
      - neural_net_architecture_design.yaml
      - model_performance_analysis.yaml
      - ... (15 m√°s)
  
  ‚úÖ Recursos curados (24):
      - "Stats for ML Engineers" (libro, quality: 0.95)
      - "Andrew Ng ML Course" (curso, quality: 0.98)
      - "FastAI Practical DL" (curso, quality: 0.92)
  
  ‚úÖ Proyectos pr√°cticos (6):
      Proyecto 1: Linear regression predictor (beginner)
      Proyecto 2: Image classifier (intermediate)
      ... (4 proyectos m√°s escalando complejidad)
  
  ‚úÖ Tiempo estimado mastery: 24 semanas (6 meses)
    ‚Üì
Usuario: "¬°Perfecto! Una ruta clara adaptada a M√ç" ‚úÖ
```

### Por Qu√© es Cr√≠tico

1. **Personalizaci√≥n Real:** An√°lisis biogr√°fico (TelescopeDB) detecta nivel REAL del usuario
2. **Eficiencia:** Evita contenido irrelevante ‚Üí ahorro de 60-80% de tiempo
3. **Multi-LLM Synergy:** Cavalry Rush combina fortalezas de 3 LLMs diferentes
4. **Progresi√≥n Estructurada:** Curriculum con pasos claros, no caos informacional
5. **Generaci√≥n de Templates:** Crea MTT-DSL templates espec√≠ficos del dominio
6. **Calidad Garantizada:** Validaci√≥n multi-LLM antes de entregar (quality > 0.85)

---

## üèóÔ∏è CONTEXTO ARQUITECT√ìNICO

### Ubicaci√≥n en el Sistema

```
FLUJO DE GENERACI√ìN DE EXPERTISE:

Usuario: "Aprende dominio X para m√≠"
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ SENSORY ENGINE (Input Processing)               ‚îÇ
‚îÇ ‚îî‚îÄ> NormalizedInput { text, domain }            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CONTEXT TOKEN 7D (Dimensional Analysis)         ‚îÇ
‚îÇ ‚îî‚îÄ> ContextTensor7D {                           ‚îÇ
‚îÇ       semantic: 0.60,      // Complejidad media ‚îÇ
‚îÇ       intentional: 0.95,   // Muy claro: learn  ‚îÇ
‚îÇ       temporal: 0.20,      // NO urgente        ‚îÇ
‚îÇ       biographical: 0.80,  // ¬°Alta relevancia! ‚îÇ
‚îÇ       ...                                       ‚îÇ
‚îÇ     }                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚òÖ‚òÖ‚òÖ EXPERTISE GENERATION (T√ö EST√ÅS AQU√ç) ‚òÖ‚òÖ‚òÖ    ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ FASE 1: An√°lisis Biogr√°fico                     ‚îÇ
‚îÇ  ‚îú‚îÄ Query TelescopeDB:                          ‚îÇ
‚îÇ  ‚îÇ   SELECT * FROM fbcu_cores                   ‚îÇ
‚îÇ  ‚îÇ   WHERE user_id = '...'                      ‚îÇ
‚îÇ  ‚îÇ   ORDER BY biographical_dimension DESC       ‚îÇ
‚îÇ  ‚îÇ   LIMIT 1000;                                ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îú‚îÄ Pattern Recognition:                        ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ Detectar dominios con queries           ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ Clasificar nivel por dominio            ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ Identificar gaps de conocimiento        ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ Mapear prerequisitos                    ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ Expertise Markers:                          ‚îÇ
‚îÇ      - Python: Expert (500+ queries)            ‚îÇ
‚îÇ      - Stats: Novice (15 queries)               ‚îÇ
‚îÇ      - ML: None (0 queries)                     ‚îÇ
‚îÇ      ‚Üí Usuario necesita ramp-up en Stats        ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ FASE 2: Cavalry Rush Deployment                 ‚îÇ
‚îÇ  üê¥ Desplegar 3 agentes especializados:         ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Agent #1: Knowledge Harvester (GPT-4)          ‚îÇ
‚îÇ   Task: "Analiza fundamentos ML + prerequisites ‚îÇ
‚îÇ          considerando nivel Python Expert"      ‚îÇ
‚îÇ   Output: Core concepts (35), prerequisites (8) ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Agent #2: Curriculum Builder (Claude 3.5)      ‚îÇ
‚îÇ   Task: "Dise√±a curriculum 0‚ÜíExpert ML          ‚îÇ
‚îÇ          considerando gap en stats"             ‚îÇ
‚îÇ   Output: 6 fases progresivas (24 semanas)      ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ  Agent #3: Resource Curator (Perplexity)        ‚îÇ
‚îÇ   Task: "Encuentra recursos high-quality 2024   ‚îÇ
‚îÇ          para curriculum ML"                    ‚îÇ
‚îÇ   Output: 24 recursos curados (quality > 0.90)  ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ FASE 3: Template Generation                     ‚îÇ
‚îÇ  ‚îú‚îÄ MTT-DSL Template Generator:                 ‚îÇ
‚îÇ  ‚îÇ   Para cada fase del curriculum:             ‚îÇ
‚îÇ  ‚îÇ   - Generar debugging template               ‚îÇ
‚îÇ  ‚îÇ   - Generar analysis template                ‚îÇ
‚îÇ  ‚îÇ   - Generar design template                  ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ Templates generados: 18                     ‚îÇ
‚îÇ      (6 fases √ó 3 templates por fase)           ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ FASE 4: Validation (LLM Council)                ‚îÇ
‚îÇ  ‚îú‚îÄ Validar con 3 LLMs independientes:          ‚îÇ
‚îÇ  ‚îÇ   ‚úì Coherencia del curriculum                ‚îÇ
‚îÇ  ‚îÇ   ‚úì Calidad de recursos                      ‚îÇ
‚îÇ  ‚îÇ   ‚úì Validez de templates                     ‚îÇ
‚îÇ  ‚îÇ                                              ‚îÇ
‚îÇ  ‚îî‚îÄ Consensus score: 0.92/1.0 ‚úÖ                ‚îÇ
‚îÇ      (Threshold m√≠nimo: 0.85)                   ‚îÇ
‚îÇ                                                 ‚îÇ
‚îÇ FASE 5: Packaging                               ‚îÇ
‚îÇ  Generar ExpertisePackage:                      ‚îÇ
‚îÇ  ‚îú‚îÄ Domain: "Machine Learning"                  ‚îÇ
‚îÇ  ‚îú‚îÄ User level: Intermediate (Python) +         ‚îÇ
‚îÇ  ‚îÇ              Novice (Stats)                  ‚îÇ
‚îÇ  ‚îú‚îÄ Curriculum: 6 fases, 24 semanas             ‚îÇ
‚îÇ  ‚îú‚îÄ Templates: 18 MTT-DSL                       ‚îÇ
‚îÇ  ‚îú‚îÄ Resources: 24 curated                       ‚îÇ
‚îÇ  ‚îú‚îÄ Projects: 6 progressive                     ‚îÇ
‚îÇ  ‚îî‚îÄ Estimated mastery: 24 weeks                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ VOXELDB (Almacenar templates generados)         ‚îÇ
‚îÇ - Indexar 18 templates ML en espacio 3D         ‚îÇ
‚îÇ - Asociar con ExpertisePackage                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ OUTPUT: ExpertisePackage                        ‚îÇ
‚îÇ - Curriculum personalizado                      ‚îÇ
‚îÇ - Templates MTT-DSL espec√≠ficos                 ‚îÇ
‚îÇ - Recursos curados                              ‚îÇ
‚îÇ - Proyectos pr√°cticos                           ‚îÇ
‚îÇ - Tiempo estimado                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
Usuario: "¬°Incre√≠ble! Ruta adaptada a m√≠" üéØ
```

### Interacciones con Otros Componentes

| Componente | Direcci√≥n | Prop√≥sito |
|------------|-----------|-----------|
| **TelescopeDB** | Consulta ‚Üî | Leer historial biogr√°fico (1000+ cores) para detectar nivel |
| **HubSpoke Navigator** | Salida ‚Üí | Coordinar Cavalry Rush (3 agentes multi-LLM) |
| **Context Token 7D** | Entrada ‚Üê | An√°lisis dimensional para personalizaci√≥n |
| **VoxelDB** | Salida ‚Üí | Almacenar templates MTT-DSL generados |
| **MTT-DSL Engine** | Salida ‚Üí | Generar templates espec√≠ficos del dominio |

---

## üìã RESPONSABILIDADES CORE

El sistema de Expertise Generation **DEBE**:

1. **An√°lisis Biogr√°fico del Usuario:**
   - Consultar TelescopeDB: √∫ltimos 1000 cores biogr√°ficos
   - Detectar dominios con actividad (queries > 10)
   - Clasificar nivel por dominio (Novice, Intermediate, Advanced, Expert, Master)
   - Identificar gaps de conocimiento (dominios relacionados faltantes)
   - Mapear prerequisitos aprendidos vs faltantes

2. **Pattern Recognition (Reconocimiento de Patrones):**
   - Analizar frecuencia de queries por dominio
   - Detectar progresi√≥n temporal (¬øest√° aprendiendo X?)
   - Identificar expertise emergente (queries cada vez m√°s complejas)
   - Calcular expertise score (0.0-1.0) por dominio:
     ```
     expertise_score = (query_count * 0.3) 
                     + (complexity_avg * 0.4) 
                     + (temporal_consistency * 0.3)
     ```

3. **Cavalry Rush Orchestration:**
   - Desplegar 3 agentes especializados (OpenAI, Anthropic, Perplexity)
   - Agent #1: Knowledge Harvester (extraer conceptos core)
   - Agent #2: Curriculum Builder (dise√±ar ruta progresiva)
   - Agent #3: Resource Curator (buscar recursos high-quality)
   - Coordinaci√≥n paralela (latencia total <10s, no 30s secuencial)

4. **Curriculum Generation:**
   - Dise√±ar fases progresivas (3-6 fases t√≠picamente)
   - Cada fase con: conceptos, ejercicios, proyectos, tiempo estimado
   - Respetar prerequisitos (Fase N no empieza si Fase N-1 incompleta)
   - Adaptaci√≥n a nivel: Beginner curriculum ‚â† Expert curriculum

5. **Template Generation (MTT-DSL):**
   - Generar 3 templates por fase del curriculum:
     * `{domain}_debugging.yaml` (troubleshooting)
     * `{domain}_analysis.yaml` (an√°lisis sistem√°tico)
     * `{domain}_design.yaml` (arquitectura/dise√±o)
   - Personalizar triggers seg√∫n dominio
   - Validar templates contra schema MTT-DSL

6. **Quality Validation (LLM Council):**
   - Validar curriculum con 3 LLMs independientes
   - Consensus threshold ‚â• 0.85 (85% acuerdo)
   - Rechazar si consensus < 0.85 ‚Üí re-generar
   - M√©tricas validadas:
     * Coherencia del curriculum
     * Calidad de recursos
     * Validez de templates
     * Progresi√≥n l√≥gica

7. **Resource Curation:**
   - Buscar recursos actuales (2024+)
   - Filtrar por quality score > 0.85
   - Diversificar tipos (art√≠culos, videos, libros, cursos)
   - Priorizar recursos gratuitos/accesibles

---

## üóÇÔ∏è ESTRUCTURAS DE DATOS

```rust
// src/expertise_generation/mod.rs

use serde::{Deserialize, Serialize};
use std::time::Duration;
use crate::core::context_token::ContextTensor7D;
use crate::cells::telescopedb::FBCUCore;

/// Motor principal de generaci√≥n de expertise
pub struct ExpertiseGenerator {
    /// Conexi√≥n a TelescopeDB (biograf√≠a)
    telescope: Arc<TelescopeDB>,
    
    /// Conexi√≥n a HubSpoke (Cavalry Rush)
    hubspoke: Arc<HubSpokeNavigator>,
    
    /// Conexi√≥n a VoxelDB (almacenar templates)
    voxel: Arc<VoxelDB>,
    
    /// Template generator MTT-DSL
    template_gen: Arc<MTTEngine>,
    
    /// Pattern recognizer (ML model local)
    pattern_recognizer: PatternRecognizer,
    
    /// Configuraci√≥n
    config: ExpertiseConfig,
    
    /// Cache de expertise packages generados
    expertise_cache: lru::LruCache<String, ExpertisePackage>,
}

/// Configuraci√≥n del generador
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ExpertiseConfig {
    /// Profundidad de an√°lisis biogr√°fico (# de cores)
    pub biographical_depth: usize,
    
    /// Threshold m√≠nimo de consensus (0.0-1.0)
    pub consensus_threshold: f64,
    
    /// Timeout para Cavalry Rush
    pub cavalry_timeout: Duration,
    
    /// Quality threshold para recursos
    pub resource_quality_threshold: f64,
    
    /// M√°ximo de templates por fase
    pub max_templates_per_phase: usize,
}

/// Request de generaci√≥n de expertise
#[derive(Debug, Clone)]
pub struct ExpertiseRequest {
    /// Usuario solicitante
    pub user_id: String,
    
    /// Dominio de expertise
    pub domain: String,
    
    /// Nivel objetivo (None = detectar autom√°ticamente)
    pub target_level: Option<ExpertiseLevel>,
    
    /// Constraint de tiempo (None = sin l√≠mite)
    pub time_constraint: Option<Duration>,
    
    /// Contexto 7D del request
    pub ctx7d: ContextTensor7D,
}

/// Niveles de expertise
#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
pub enum ExpertiseLevel {
    AbsoluteBeginner = 0,  // üê£ Cero conocimiento
    Beginner = 1,          // üê§ Conocimiento b√°sico
    Novice = 2,            // üê• Entiende fundamentos
    Intermediate = 3,      // ü¶Ü Puede aplicar
    Advanced = 4,          // ü¶Ö Domina avanzado
    Expert = 5,            // ü¶â Puede ense√±ar
    Master = 6,            // üßô Innova en el campo
}

impl ExpertiseLevel {
    /// Convertir query count ‚Üí nivel aproximado
    pub fn from_query_count(count: usize) -> Self {
        match count {
            0..=5 => Self::AbsoluteBeginner,
            6..=20 => Self::Beginner,
            21..=50 => Self::Novice,
            51..=150 => Self::Intermediate,
            151..=400 => Self::Advanced,
            401..=1000 => Self::Expert,
            _ => Self::Master,
        }
    }
}

/// Package completo de expertise generado
#[derive(Debug, Clone, Serialize)]
pub struct ExpertisePackage {
    /// Dominio del expertise
    pub domain: String,
    
    /// Nivel detectado del usuario
    pub current_level: ExpertiseLevel,
    
    /// Nivel objetivo
    pub target_level: ExpertiseLevel,
    
    /// Curriculum progresivo
    pub curriculum: Curriculum,
    
    /// Templates MTT-DSL generados
    pub templates: Vec<GeneratedTemplate>,
    
    /// Knowledge base del dominio
    pub knowledge_base: KnowledgeBase,
    
    /// Recursos curados
    pub resources: Vec<CuratedResource>,
    
    /// Proyectos pr√°cticos
    pub projects: Vec<PracticalProject>,
    
    /// Tiempo estimado de mastery
    pub estimated_mastery_time: Duration,
    
    /// Metadata de generaci√≥n
    pub metadata: ExpertiseMetadata,
}

/// Curriculum progresivo
#[derive(Debug, Clone, Serialize)]
pub struct Curriculum {
    /// Nombre del curriculum
    pub name: String,
    
    /// Fases del curriculum (ordenadas)
    pub phases: Vec<CurriculumPhase>,
    
    /// Score de complejidad total (0.0-1.0)
    pub complexity_score: f64,
    
    /// Prerequisitos globales
    pub prerequisites: Vec<String>,
}

/// Fase del curriculum
#[derive(Debug, Clone, Serialize)]
pub struct CurriculumPhase {
    /// N√∫mero de fase (1-indexed)
    pub phase_number: usize,
    
    /// Nombre de la fase
    pub name: String,
    
    /// Descripci√≥n
    pub description: String,
    
    /// Nivel de dificultad (0.0-1.0)
    pub difficulty: f64,
    
    /// Conceptos a aprender en esta fase
    pub concepts: Vec<Concept>,
    
    /// Ejercicios pr√°cticos
    pub exercises: Vec<Exercise>,
    
    /// Proyecto de fase
    pub project: Option<PracticalProject>,
    
    /// Horas estimadas
    pub estimated_hours: u64,
    
    /// Prerequisitos de esta fase
    pub prerequisites: Vec<String>,
}

/// Concepto a aprender
#[derive(Debug, Clone, Serialize)]
pub struct Concept {
    /// Nombre del concepto
    pub name: String,
    
    /// Descripci√≥n
    pub description: String,
    
    /// Dificultad (0.0-1.0)
    pub difficulty: f64,
    
    /// Prerequisitos
    pub prerequisites: Vec<String>,
    
    /// Conceptos relacionados
    pub related_concepts: Vec<String>,
    
    /// Ejemplos
    pub examples: Vec<String>,
}

/// Ejercicio pr√°ctico
#[derive(Debug, Clone, Serialize)]
pub struct Exercise {
    /// T√≠tulo del ejercicio
    pub title: String,
    
    /// Descripci√≥n
    pub description: String,
    
    /// Dificultad (0.0-1.0)
    pub difficulty: f64,
    
    /// Tiempo estimado (minutos)
    pub estimated_minutes: u32,
    
    /// Hints
    pub hints: Vec<String>,
    
    /// Soluci√≥n (opcional)
    pub solution: Option<String>,
}

/// Proyecto pr√°ctico
#[derive(Debug, Clone, Serialize)]
pub struct PracticalProject {
    /// T√≠tulo del proyecto
    pub title: String,
    
    /// Descripci√≥n completa
    pub description: String,
    
    /// Objetivos de aprendizaje
    pub learning_objectives: Vec<String>,
    
    /// Tecnolog√≠as usadas
    pub technologies: Vec<String>,
    
    /// Dificultad (0.0-1.0)
    pub difficulty: f64,
    
    /// Tiempo estimado (horas)
    pub estimated_hours: u64,
    
    /// Pasos del proyecto
    pub steps: Vec<ProjectStep>,
    
    /// Criterios de validaci√≥n
    pub validation_criteria: Vec<String>,
}

/// Paso de proyecto
#[derive(Debug, Clone, Serialize)]
pub struct ProjectStep {
    /// N√∫mero de paso (1-indexed)
    pub step_number: usize,
    
    /// Descripci√≥n del paso
    pub description: String,
    
    /// C√≥digo de ejemplo (opcional)
    pub code_example: Option<String>,
    
    /// Validaci√≥n de este paso
    pub validation: Option<String>,
}

/// Knowledge base del dominio
#[derive(Debug, Clone, Serialize)]
pub struct KnowledgeBase {
    /// Dominio
    pub domain: String,
    
    /// Conceptos core (fundamentales)
    pub core_concepts: Vec<Concept>,
    
    /// Best practices
    pub best_practices: Vec<BestPractice>,
    
    /// Common mistakes
    pub common_mistakes: Vec<CommonMistake>,
    
    /// Glosario de t√©rminos
    pub glossary: Vec<GlossaryTerm>,
}

/// Best practice
#[derive(Debug, Clone, Serialize)]
pub struct BestPractice {
    pub title: String,
    pub description: String,
    pub importance: f64,  // 0.0-1.0
    pub examples: Vec<String>,
}

/// Common mistake
#[derive(Debug, Clone, Serialize)]
pub struct CommonMistake {
    pub mistake: String,
    pub explanation: String,
    pub how_to_avoid: String,
    pub correct_approach: String,
}

/// T√©rmino de glosario
#[derive(Debug, Clone, Serialize)]
pub struct GlossaryTerm {
    pub term: String,
    pub definition: String,
    pub examples: Vec<String>,
}

/// Recurso curado
#[derive(Debug, Clone, Serialize)]
pub struct CuratedResource {
    /// T√≠tulo del recurso
    pub title: String,
    
    /// Tipo de recurso
    pub resource_type: ResourceType,
    
    /// URL (si aplica)
    pub url: Option<String>,
    
    /// Descripci√≥n
    pub description: String,
    
    /// Quality score (0.0-1.0)
    pub quality_score: f64,
    
    /// Nivel recomendado
    pub recommended_level: ExpertiseLevel,
    
    /// Tiempo estimado (horas)
    pub estimated_hours: Option<u64>,
    
    /// Es gratuito
    pub is_free: bool,
}

/// Tipos de recursos
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub enum ResourceType {
    Article,
    Video,
    Book,
    Course,
    Documentation,
    Tutorial,
    Paper,
    Podcast,
    Tool,
}

/// Template MTT-DSL generado
#[derive(Debug, Clone, Serialize)]
pub struct GeneratedTemplate {
    /// ID del template
    pub template_id: String,
    
    /// Nombre humano-legible
    pub name: String,
    
    /// Categor√≠a
    pub category: String,
    
    /// Path donde se guard√≥
    pub file_path: String,
    
    /// Contenido YAML del template
    pub yaml_content: String,
    
    /// Quality score (0.0-1.0)
    pub quality_score: f64,
}

/// Metadata de generaci√≥n
#[derive(Debug, Clone, Serialize)]
pub struct ExpertiseMetadata {
    /// Timestamp de generaci√≥n
    pub generated_at: i64,
    
    /// Tiempo que tom√≥ generar (ms)
    pub generation_time_ms: u64,
    
    /// Cavalry agents usados
    pub cavalry_agents: Vec<String>,
    
    /// Consensus score final
    pub consensus_score: f64,
    
    /// # de cores biogr√°ficos analizados
    pub biographical_cores_analyzed: usize,
    
    /// Versi√≥n del generador
    pub generator_version: String,
}

/// Pattern recognizer (ML local)
pub struct PatternRecognizer {
    /// Modelo de clasificaci√≥n de nivel
    level_classifier: Box<dyn Fn(&[FBCUCore]) -> ExpertiseLevel>,
    
    /// Detector de gaps de conocimiento
    gap_detector: Box<dyn Fn(&[FBCUCore]) -> Vec<String>>,
}
```

---

## üîå API P√öBLICA

```rust
// src/expertise_generation/mod.rs

impl ExpertiseGenerator {
    /// Crear nuevo generador
    pub fn new(config: ExpertiseConfig) -> Result<Self> {
        Ok(Self {
            telescope: Arc::new(TelescopeDB::new()?),
            hubspoke: Arc::new(HubSpokeNavigator::new(default_hubspoke_config())?),
            voxel: Arc::new(VoxelDB::new()?),
            template_gen: Arc::new(MTTEngine::new(default_mtt_config())?),
            pattern_recognizer: PatternRecognizer::new(),
            config,
            expertise_cache: lru::LruCache::new(100),
        })
    }
    
    /// Generar expertise completa para un dominio
    /// 
    /// # Argumentos
    /// - `request`: Request con dominio, user_id, nivel objetivo
    /// 
    /// # Retorna
    /// `ExpertisePackage` completo con curriculum, templates, recursos
    /// 
    /// # Ejemplo
    /// ```rust
    /// let request = ExpertiseRequest {
    ///     user_id: "user_123".to_string(),
    ///     domain: "machine_learning".to_string(),
    ///     target_level: Some(ExpertiseLevel::Expert),
    ///     time_constraint: Some(Duration::from_secs(3600 * 24 * 180)), // 6 meses
    ///     ctx7d: ContextTensor7D::default(),
    /// };
    /// 
    /// let package = generator.generate_expertise(request).await?;
    /// println!("Curriculum generado: {} fases", package.curriculum.phases.len());
    /// ```
    pub async fn generate_expertise(
        &mut self,
        request: ExpertiseRequest,
    ) -> Result<ExpertisePackage> {
        let start = Instant::now();
        
        // Revisar cache primero
        let cache_key = format!("{}:{}", request.user_id, request.domain);
        if let Some(cached) = self.expertise_cache.get(&cache_key) {
            return Ok(cached.clone());
        }
        
        // FASE 1: An√°lisis biogr√°fico
        let biographical_analysis = self.analyze_user_biography(&request).await?;
        
        // FASE 2: Cavalry Rush
        let cavalry_results = self.deploy_cavalry_rush(&request, &biographical_analysis).await?;
        
        // FASE 3: Curriculum generation
        let curriculum = self.build_curriculum(&cavalry_results, &biographical_analysis)?;
        
        // FASE 4: Template generation
        let templates = self.generate_templates(&curriculum, &request.domain).await?;
        
        // FASE 5: Validation (LLM Council)
        let validated_package = self.validate_with_llm_council(
            &curriculum,
            &templates,
            &cavalry_results.resources,
        ).await?;
        
        // FASE 6: Packaging
        let package = ExpertisePackage {
            domain: request.domain.clone(),
            current_level: biographical_analysis.current_level,
            target_level: request.target_level
                .unwrap_or(ExpertiseLevel::Expert),
            curriculum,
            templates,
            knowledge_base: cavalry_results.knowledge_base,
            resources: cavalry_results.resources,
            projects: cavalry_results.projects,
            estimated_mastery_time: self.calculate_mastery_time(&curriculum),
            metadata: ExpertiseMetadata {
                generated_at: chrono::Utc::now().timestamp(),
                generation_time_ms: start.elapsed().as_millis() as u64,
                cavalry_agents: cavalry_results.agents_used,
                consensus_score: validated_package.consensus_score,
                biographical_cores_analyzed: biographical_analysis.cores_analyzed,
                generator_version: env!("CARGO_PKG_VERSION").to_string(),
            },
        };
        
        // Cachear resultado
        self.expertise_cache.put(cache_key, package.clone());
        
        // Almacenar templates en VoxelDB
        self.store_templates_in_voxel(&package).await?;
        
        Ok(package)
    }
    
    /// Analizar biograf√≠a del usuario (TelescopeDB)
    async fn analyze_user_biography(
        &self,
        request: &ExpertiseRequest,
    ) -> Result<BiographicalAnalysis> {
        // Consultar TelescopeDB: √∫ltimos N cores
        let cores = self.telescope
            .query_biographical(&request.user_id, self.config.biographical_depth)
            .await?;
        
        // Pattern recognition
        let domain_patterns = self.pattern_recognizer.analyze_domains(&cores);
        
        // Detectar nivel actual en dominio solicitado
        let current_level = domain_patterns
            .get(&request.domain)
            .map(|p| p.level)
            .unwrap_or(ExpertiseLevel::AbsoluteBeginner);
        
        // Detectar gaps
        let knowledge_gaps = self.pattern_recognizer.detect_gaps(&cores, &request.domain);
        
        Ok(BiographicalAnalysis {
            user_id: request.user_id.clone(),
            cores_analyzed: cores.len(),
            current_level,
            domain_patterns,
            knowledge_gaps,
            strong_domains: self.extract_strong_domains(&domain_patterns),
            weak_domains: self.extract_weak_domains(&domain_patterns),
        })
    }
    
    /// Desplegar Cavalry Rush (3 agentes multi-LLM)
    async fn deploy_cavalry_rush(
        &self,
        request: &ExpertiseRequest,
        bio_analysis: &BiographicalAnalysis,
    ) -> Result<CavalryResults> {
        tracing::info!(
            "Desplegando Cavalry Rush para dominio: {}",
            request.domain
        );
        
        // Agent #1: Knowledge Harvester (GPT-4)
        let knowledge_task = self.hubspoke.route_to_provider(
            LLMProvider::OpenAI,
            &format!(
                "Analiza fundamentos de {} considerando:\n\
                 - Nivel actual: {:?}\n\
                 - Dominios fuertes: {:?}\n\
                 - Gaps: {:?}\n\
                 Extrae: conceptos core, prerequisitos, t√©rminos clave",
                request.domain,
                bio_analysis.current_level,
                bio_analysis.strong_domains,
                bio_analysis.knowledge_gaps
            ),
        );
        
        // Agent #2: Curriculum Builder (Claude 3.5)
        let curriculum_task = self.hubspoke.route_to_provider(
            LLMProvider::Anthropic,
            &format!(
                "Dise√±a curriculum progresivo 0‚ÜíExpert para {}\n\
                 Considera:\n\
                 - Usuario empieza en: {:?}\n\
                 - Debe cubrir gaps: {:?}\n\
                 Output: 4-6 fases con conceptos, ejercicios, tiempo estimado",
                request.domain,
                bio_analysis.current_level,
                bio_analysis.knowledge_gaps
            ),
        );
        
        // Agent #3: Resource Curator (Perplexity)
        let resources_task = self.hubspoke.route_to_provider(
            LLMProvider::Perplexity,
            &format!(
                "Busca recursos high-quality 2024+ para aprender {}\n\
                 Niveles: Beginner ‚Üí Expert\n\
                 Tipos: art√≠culos, videos, cursos, libros, docs\n\
                 Prioriza: gratuitos, actuales, bien valorados",
                request.domain
            ),
        );
        
        // Ejecutar en paralelo (latencia ~8-12s vs ~30s secuencial)
        let (knowledge_result, curriculum_result, resources_result) = tokio::join!(
            knowledge_task,
            curriculum_task,
            resources_task
        );
        
        Ok(CavalryResults {
            knowledge_base: Self::parse_knowledge_base(knowledge_result?)?,
            raw_curriculum: curriculum_result?,
            resources: Self::parse_resources(resources_result?)?,
            projects: Self::extract_projects(&curriculum_result?),
            agents_used: vec![
                "OpenAI GPT-4".to_string(),
                "Anthropic Claude 3.5".to_string(),
                "Perplexity Sonar".to_string(),
            ],
        })
    }
    
    /// Construir curriculum a partir de resultados Cavalry
    fn build_curriculum(
        &self,
        cavalry: &CavalryResults,
        bio: &BiographicalAnalysis,
    ) -> Result<Curriculum> {
        // Parsear raw curriculum de Claude
        let phases = Self::parse_curriculum_phases(&cavalry.raw_curriculum)?;
        
        // Ajustar fases seg√∫n nivel actual
        let adjusted_phases = if bio.current_level > ExpertiseLevel::Beginner {
            // Saltar fases que usuario ya domina
            phases.into_iter()
                .filter(|phase| phase.difficulty > bio.current_level as i32 as f64 * 0.15)
                .collect()
        } else {
            phases
        };
        
        // Calcular complejidad total
        let complexity_score = adjusted_phases.iter()
            .map(|p| p.difficulty)
            .sum::<f64>() / adjusted_phases.len() as f64;
        
        Ok(Curriculum {
            name: format!("{} - Curriculum Personalizado", cavalry.raw_curriculum),
            phases: adjusted_phases,
            complexity_score,
            prerequisites: bio.knowledge_gaps.clone(),
        })
    }
    
    /// Generar templates MTT-DSL por fase
    async fn generate_templates(
        &self,
        curriculum: &Curriculum,
        domain: &str,
    ) -> Result<Vec<GeneratedTemplate>> {
        let mut templates = Vec::new();
        
        for phase in &curriculum.phases {
            // 3 templates por fase
            let template_types = ["debugging", "analysis", "design"];
            
            for template_type in &template_types {
                let template_yaml = self.template_gen.generate_template(
                    domain,
                    phase,
                    template_type,
                ).await?;
                
                let template_id = format!(
                    "{}_{}_phase{}_{}",
                    domain,
                    template_type,
                    phase.phase_number,
                    chrono::Utc::now().timestamp()
                );
                
                let file_path = format!(
                    "templates/mtt/generated/{}/{}.yaml",
                    domain,
                    template_id
                );
                
                // Guardar template
                std::fs::create_dir_all(format!("templates/mtt/generated/{}", domain))?;
                std::fs::write(&file_path, &template_yaml)?;
                
                templates.push(GeneratedTemplate {
                    template_id: template_id.clone(),
                    name: format!("{} {} - Fase {}", domain, template_type, phase.phase_number),
                    category: "generated".to_string(),
                    file_path,
                    yaml_content: template_yaml,
                    quality_score: 0.90, // Validado despu√©s
                });
            }
        }
        
        Ok(templates)
    }
    
    /// Validar con LLM Council (3 LLMs independientes)
    async fn validate_with_llm_council(
        &self,
        curriculum: &Curriculum,
        templates: &[GeneratedTemplate],
        resources: &[CuratedResource],
    ) -> Result<ValidatedPackage> {
        let validation_prompt = format!(
            "Valida este expertise package:\n\
             - Curriculum: {} fases\n\
             - Templates: {} generados\n\
             - Recursos: {} curados\n\n\
             Criterios:\n\
             1. Coherencia del curriculum (l√≥gica de progresi√≥n)\n\
             2. Calidad de templates (estructura MTT-DSL)\n\
             3. Relevancia de recursos (actuales, high-quality)\n\n\
             Output: Score 0.0-1.0 + justificaci√≥n",
            curriculum.phases.len(),
            templates.len(),
            resources.len()
        );
        
        // Validar con 3 LLMs
        let (v1, v2, v3) = tokio::join!(
            self.hubspoke.route_to_provider(LLMProvider::OpenAI, &validation_prompt),
            self.hubspoke.route_to_provider(LLMProvider::Anthropic, &validation_prompt),
            self.hubspoke.route_to_provider(LLMProvider::Perplexity, &validation_prompt)
        );
        
        // Extraer scores
        let score1 = Self::extract_validation_score(&v1?)?;
        let score2 = Self::extract_validation_score(&v2?)?;
        let score3 = Self::extract_validation_score(&v3?)?;
        
        // Consensus = promedio
        let consensus_score = (score1 + score2 + score3) / 3.0;
        
        if consensus_score < self.config.consensus_threshold {
            return Err(Error::ConsensusThresholdNotMet {
                score: consensus_score,
                threshold: self.config.consensus_threshold,
            });
        }
        
        Ok(ValidatedPackage {
            consensus_score,
            individual_scores: vec![score1, score2, score3],
        })
    }
    
    /// Almacenar templates en VoxelDB
    async fn store_templates_in_voxel(&self, package: &ExpertisePackage) -> Result<()> {
        for template in &package.templates {
            // Convertir dominio ‚Üí coordenadas 3D
            let coords = self.domain_to_coords(&package.domain, template);
            
            self.voxel.insert_template(Template {
                name: template.name.clone(),
                coords,
                content: template.yaml_content.clone(),
                metadata: TemplateMetadata {
                    domain: package.domain.clone(),
                    quality_score: template.quality_score,
                    generated_at: package.metadata.generated_at,
                },
            }).await?;
        }
        
        Ok(())
    }
    
    /// Calcular tiempo estimado de mastery
    fn calculate_mastery_time(&self, curriculum: &Curriculum) -> Duration {
        let total_hours: u64 = curriculum.phases.iter()
            .map(|p| p.estimated_hours)
            .sum();
        
        Duration::from_secs(total_hours * 3600)
    }
}
```

---

## ‚öôÔ∏è IMPLEMENTACI√ìN INTERNA

### Algoritmo: Pattern Recognition (An√°lisis Biogr√°fico)

```rust
impl PatternRecognizer {
    /// Analizar dominios desde cores biogr√°ficos
    pub fn analyze_domains(&self, cores: &[FBCUCore]) -> HashMap<String, DomainPattern> {
        let mut domain_map: HashMap<String, Vec<&FBCUCore>> = HashMap::new();
        
        // Agrupar cores por dominio
        for core in cores {
            // Extraer dominio desde content
            if let Some(domain) = self.extract_domain(&core.content) {
                domain_map.entry(domain).or_insert_with(Vec::new).push(core);
            }
        }
        
        // Calcular patterns por dominio
        domain_map.into_iter()
            .map(|(domain, domain_cores)| {
                let pattern = self.calculate_domain_pattern(&domain_cores);
                (domain, pattern)
            })
            .collect()
    }
    
    fn calculate_domain_pattern(&self, cores: &[&FBCUCore]) -> DomainPattern {
        let query_count = cores.len();
        
        // Complejidad promedio
        let avg_complexity = cores.iter()
            .map(|c| c.context_tensor.semantic)
            .sum::<f64>() / query_count as f64;
        
        // Consistencia temporal (¬øqueries distribuidas o concentradas?)
        let temporal_consistency = self.calculate_temporal_consistency(cores);
        
        // Nivel estimado
        let level = ExpertiseLevel::from_query_count(query_count);
        
        // Expertise score
        let expertise_score = (query_count as f64 * 0.001).min(0.3)  // Max 0.3 por count
                            + (avg_complexity * 0.4)                   // Max 0.4 por complexity
                            + (temporal_consistency * 0.3);             // Max 0.3 por consistency
        
        DomainPattern {
            domain: cores[0].content.clone(), // Placeholder
            query_count,
            avg_complexity,
            temporal_consistency,
            level,
            expertise_score,
        }
    }
    
    fn calculate_temporal_consistency(&self, cores: &[&FBCUCore]) -> f64 {
        if cores.len() < 2 {
            return 0.0;
        }
        
        // Calcular intervalos entre queries
        let mut timestamps: Vec<i64> = cores.iter()
            .map(|c| c.timestamp)
            .collect();
        timestamps.sort();
        
        let intervals: Vec<i64> = timestamps.windows(2)
            .map(|w| w[1] - w[0])
            .collect();
        
        // Consistencia = 1.0 - varianza normalizada
        let mean_interval = intervals.iter().sum::<i64>() / intervals.len() as i64;
        let variance = intervals.iter()
            .map(|i| ((i - mean_interval) as f64).powi(2))
            .sum::<f64>() / intervals.len() as f64;
        
        let std_dev = variance.sqrt();
        let coefficient_variation = std_dev / mean_interval as f64;
        
        (1.0 - coefficient_variation).max(0.0).min(1.0)
    }
}
```

---

## üîó DEPENDENCIAS

### Componentes de Bit√°cora

| Componente | Versi√≥n | Prop√≥sito |
|------------|---------|-----------|
| **TelescopeDB** | v1.0 | Consultar biograf√≠a (1000 cores) para pattern recognition |
| **HubSpoke Navigator** | v1.0 | Coordinar Cavalry Rush (3 agentes multi-LLM) |
| **Context Token 7D** | v1.0 | An√°lisis dimensional del request |
| **VoxelDB** | v1.0 | Almacenar templates MTT-DSL generados |
| **MTT-DSL Engine** | v1.0 | Generar templates espec√≠ficos del dominio |

### Crates Externos

```toml
[dependencies]
# Core async
tokio = { version = "1.35", features = ["full"] }

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"

# HTTP client (para Cavalry Rush APIs)
reqwest = { version = "0.11", features = ["json"] }

# Caching
lru = "0.12"

# ML pattern recognition (local)
ndarray = "0.15"
linfa = "0.7"  # ML algorithms

# Error handling
thiserror = "1.0"
anyhow = "1.0"

# Logging
tracing = "0.1"

# Datetime
chrono = { version = "0.4", features = ["serde"] }
```

---

## ‚ö° OBJETIVOS DE PERFORMANCE

| Operaci√≥n | Target | Medici√≥n | Status |
|-----------|--------|----------|--------|
| `analyze_user_biography()` | <500ms | An√°lisis de 1000 cores biogr√°ficos | ‚è∏Ô∏è TBD |
| `deploy_cavalry_rush()` | <12s | Coordinar 3 agentes multi-LLM en paralelo | üéØ CR√çTICO |
| `build_curriculum()` | <200ms | Parsear + ajustar curriculum | ‚è∏Ô∏è TBD |
| `generate_templates()` | <5s | Generar 18 templates MTT-DSL | ‚è∏Ô∏è TBD |
| `validate_with_llm_council()` | <10s | Validar con 3 LLMs en paralelo | ‚è∏Ô∏è TBD |
| **Pipeline total** | **<30s** | **Desde request hasta ExpertisePackage** | **üéØ CR√çTICO** |
| Memoria RAM (Generator) | <200 MB | RSS con cache de 100 packages | ‚è∏Ô∏è TBD |
| **Consensus score** | **‚â•0.85** | **Threshold m√≠nimo de validaci√≥n** | **üéØ CR√çTICO** |

---

## üß™ ESTRATEGIA DE TESTING

### Unit Tests

```rust
// tests/expertise_generation_test.rs

#[tokio::test]
async fn test_biographical_analysis_detects_python_expert() {
    let generator = ExpertiseGenerator::new(default_config()).unwrap();
    
    // Mock: 500 cores sobre Python
    let python_cores = create_mock_cores("python", 500, 0.75);
    
    let analysis = generator.pattern_recognizer
        .analyze_domains(&python_cores);
    
    let python_pattern = analysis.get("python").unwrap();
    assert!(python_pattern.level >= ExpertiseLevel::Expert);
    assert!(python_pattern.expertise_score > 0.80);
}

#[tokio::test]
async fn test_curriculum_adapts_to_user_level() {
    let generator = ExpertiseGenerator::new(default_config()).unwrap();
    
    // Usuario Intermediate en Python, Beginner en ML
    let bio = BiographicalAnalysis {
        current_level: ExpertiseLevel::Intermediate,
        ..Default::default()
    };
    
    let cavalry = mock_cavalry_results();
    let curriculum = generator.build_curriculum(&cavalry, &bio).unwrap();
    
    // Curriculum debe saltar fases beginner
    assert!(curriculum.phases[0].difficulty > 0.30);
    assert_eq!(curriculum.phases.len(), 4); // Menos fases que curriculum completo (6)
}
```

### Integration Tests

```rust
// tests/integration/cavalry_rush_integration.rs

#[tokio::test]
async fn test_cavalry_rush_generates_valid_curriculum() {
    let generator = ExpertiseGenerator::new(default_config()).unwrap();
    
    let request = ExpertiseRequest {
        user_id: "test_user".to_string(),
        domain: "rust_programming".to_string(),
        target_level: Some(ExpertiseLevel::Expert),
        time_constraint: None,
        ctx7d: ContextTensor7D::default(),
    };
    
    let bio = BiographicalAnalysis {
        current_level: ExpertiseLevel::Beginner,
        cores_analyzed: 1000,
        knowledge_gaps: vec!["ownership".to_string(), "lifetimes".to_string()],
        ..Default::default()
    };
    
    let cavalry_results = generator.deploy_cavalry_rush(&request, &bio)
        .await.unwrap();
    
    // Validaciones
    assert!(!cavalry_results.knowledge_base.core_concepts.is_empty());
    assert!(cavalry_results.resources.len() >= 10);
    assert_eq!(cavalry_results.agents_used.len(), 3);
}
```

---

## ‚ö†Ô∏è MANEJO DE ERRORES

```rust
// src/expertise_generation/error.rs

use thiserror::Error;

#[derive(Debug, Error)]
pub enum ExpertiseError {
    #[error("Biograf√≠a insuficiente: solo {0} cores analizados (m√≠nimo: {1})")]
    InsufficientBiography(usize, usize),
    
    #[error("Cavalry Rush fall√≥: {0}")]
    CavalryDeploymentFailed(String),
    
    #[error("Consensus threshold no alcanzado: {score:.2} < {threshold:.2}")]
    ConsensusThresholdNotMet { score: f64, threshold: f64 },
    
    #[error("Template generation fall√≥ para dominio {0}: {1}")]
    TemplateGenerationFailed(String, String),
    
    #[error("Curriculum parsing fall√≥: {0}")]
    CurriculumParsingFailed(String),
    
    #[error("Dominio no reconocido: {0}")]
    UnknownDomain(String),
    
    #[error("Error de TelescopeDB: {0}")]
    TelescopeDBError(#[from] crate::cells::telescopedb::Error),
    
    #[error("Error de VoxelDB: {0}")]
    VoxelDBError(#[from] crate::cells::voxeldb::Error),
    
    #[error("Error de HubSpoke: {0}")]
    HubSpokeError(#[from] crate::multi_agent::hubspoke::Error),
}

pub type Result<T> = std::result::Result<T, ExpertiseError>;
```

---

## üìö REFERENCIAS

### Documentos ROADMAP_V2

- **ROADMAP_V2/02_COMPONENTES/CRITICOS/TELESCOPEDB.md** - Consulta biogr√°fica para pattern recognition
- **ROADMAP_V2/02_COMPONENTES/IMPORTANTES/HUBSPOKE_NAVIGATOR.md** - Cavalry Rush multi-LLM
- **ROADMAP_V2/02_COMPONENTES/IMPORTANTES/MTT_DSL_TEMPLATES.md** - Generaci√≥n de templates
- **ROADMAP_V2/02_COMPONENTES/CRITICOS/VOXELDB.md** - Almacenamiento de templates generados

### Decisiones Arquitect√≥nicas

- **DA-027:** Expertise Generation desde TelescopeDB (dimensi√≥n biogr√°fica)
- **DA-010:** Cavalry Rush System (multi-agent orchestration)
- **BITA-2:** ACA-7D Biographical Dimension Analysis

### FUSION_BAYESIANA

- **FUSION_BAYESIANA/02_GAP_ANALYSIS.md** (Brecha #6) - Expertise Generation como brecha ALTA
- **FUSION_BAYESIANA/07_PLAN_IMPLEMENTACION.md** (Semanas 11-12) - Plan de implementaci√≥n
- **FUSION_BAYESIANA/08_DIAGRAMA_SISTEMA.md** (Layer 3) - Ubicaci√≥n en arquitectura

### C√≥digo Existente

- `src/expertise_generation/mod.rs` - Motor base (estructura existente)
- `src/expertise_generation/cavalry_rush.rs` - Cavalry Rush implementation
- `src/multi_agent/core.rs` - Sistema multi-agente base

---

## üöÄ PR√ìXIMOS PASOS

### Implementaci√≥n Inmediata (Semanas 11-12)

1. **Completar pattern recognizer:**
   - Implementar `analyze_domains()` con ML local
   - Entrenar clasificador de nivel (query_count ‚Üí ExpertiseLevel)
   - Detector de gaps (dominios faltantes)
   - Unit tests con mock cores

2. **Integrar Cavalry Rush:**
   - Conectar con HubSpoke Navigator
   - Implementar coordinaci√≥n paralela (tokio::join!)
   - Timeout handling (12s max)
   - Parsear resultados de LLMs

3. **Curriculum builder:**
   - Parser de resultados de Claude
   - Ajuste por nivel del usuario
   - Generaci√≥n de ejercicios
   - C√°lculo de tiempo estimado

4. **Template generator:**
   - Integrar con MTT-DSL Engine
   - Generar 3 templates por fase
   - Validar contra schema YAML
   - Almacenar en VoxelDB

5. **LLM Council validation:**
   - Coordinar 3 validaciones paralelas
   - Extraer consensus score
   - Threshold checking (‚â•0.85)
   - Re-generaci√≥n si falla

### Mejoras v1.5 (Semanas 13-14)

6. **Resource curation avanzado:**
   - Integrar Perplexity para b√∫squeda real-time
   - Filtrar por fecha (2024+)
   - Quality scoring (reviews, ratings)
   - Priorizar gratuitos

7. **Interactive elements:**
   - Simulaciones por fase
   - Gamification (XP, achievements)
   - Assessments autom√°ticos
   - Progress tracking

8. **Optimizaciones:**
   - Cache de domain patterns (LRU 1000 entries)
   - Paralelizaci√≥n de template generation (Rayon)
   - Reducir latencia Cavalry Rush (<8s)

### Mejoras v2.0 (Futuro)

9. **ML avanzado:**
   - Entrenar modelo predictivo de expertise
   - Transfer learning entre dominios
   - Personalizaci√≥n continua (feedback loop)

10. **Multi-domain expertise:**
    - Generar curriculum interdisciplinario
    - Detectar sinergias entre dominios
    - Pathways de carrera (backend ‚Üí full-stack ‚Üí architect)

11. **Community-driven:**
    - Compartir expertise packages entre usuarios
    - Voting/rating de curriculum
    - Contribuciones de expertos humanos

---

**Estado:** üìã ESPECIFICACI√ìN  
**Complejidad:** üî¥ ALTA (Cavalry Rush + ML + Multi-LLM validation)  
**Prioridad:** üü° ALTA (Fase 2, Semanas 11-12)

---

*Generado: 2025-10-26*  
*Sistema Bit√°cora v1.0 - MTT-DSL Template: component_spec*
