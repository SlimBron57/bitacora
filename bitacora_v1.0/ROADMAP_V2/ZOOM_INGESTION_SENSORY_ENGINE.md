# ğŸ” ZOOM: PROCESO DE INGESTION - SENSORY ENGINE DETALLADO

**Fecha:** 2025-10-28 15:45h  
**Componente:** SENSORY ENGINE (aka "Ingestion Engine" en FUSION_BAYESIANA)  
**Estado Actual:** âœ… v1.0 Implementado (monolÃ­tico)  
**Estado Futuro:** ğŸ”„ v2.0 Refactor (modular + templates)

---

## ğŸ“Š VISIÃ“N GENERAL DEL FLUJO

```mermaid
graph TD
    START([ğŸ¤ Input Multimodal]) --> ROUTER{SENSORY ROUTER}
    
    ROUTER -->|Audio| AUDIO[ğŸµ Audio Processor]
    ROUTER -->|Text| TEXT[ğŸ“ Text Processor]
    ROUTER -->|Visual| VISUAL[ğŸ–¼ï¸ Visual Processor]
    
    AUDIO --> WHISPER[Whisper API<br/>Transcription]
    TEXT --> DIRECT[Direct Input<br/>Already Text]
    VISUAL --> VISION[Vision API<br/>Imageâ†’Description]
    
    WHISPER --> NORMALIZE[ğŸ§¬ Normalization Engine]
    DIRECT --> NORMALIZE
    VISION --> NORMALIZE
    
    NORMALIZE --> LANG[ğŸŒ Language Detection]
    NORMALIZE --> SENT[ğŸ˜Š Sentiment Analysis]
    NORMALIZE --> ENT[ğŸ·ï¸ Entity Recognition]
    NORMALIZE --> EMO[ğŸ’— Emotion Detection]
    
    LANG --> CTX7D[ğŸ“ ContextToken 7D]
    SENT --> CTX7D
    ENT --> CTX7D
    EMO --> CTX7D
    
    CTX7D --> OUTPUT([ğŸ¯ Normalized Output])
    
    style START fill:#e1f5ff,stroke:#0066cc
    style ROUTER fill:#fff3cd,stroke:#f0ad4e
    style NORMALIZE fill:#d4edda,stroke:#28a745
    style CTX7D fill:#f8d7da,stroke:#dc3545
    style OUTPUT fill:#d1ecf1,stroke:#17a2b8
```

---

## ğŸ”¬ ANÃLISIS DETALLADO POR CAPA

### ğŸ¯ CAPA 1: ENTRADA MULTIMODAL

```rust
// src/sensory_engine/mod.rs (v1.0)

pub enum SensoryInput {
    Audio {
        data: Vec<u8>,
        format: AudioFormat,  // MP3, WAV, OGG, FLAC
        sample_rate: u32,
    },
    Text {
        content: String,
        encoding: TextEncoding,  // UTF-8, UTF-16
    },
    Visual {
        image: Vec<u8>,
        format: ImageFormat,  // PNG, JPEG, WEBP
        dimensions: (u32, u32),
    },
}
```

**CaracterÃ­sticas:**
- âœ… **Tipado fuerte:** Enum para seguridad en compile-time
- âœ… **Metadatos:** Formato, sample rate, dimensiones
- âš ï¸ **LimitaciÃ³n v1.0:** Solo audio/text/visual (no video, no docs)

---

### ğŸµ CAPA 2: AUDIO PROCESSOR

```rust
// src/sensory_engine/mod.rs (lÃ­neas 45-95)

pub struct AudioProcessor {
    whisper_api_key: String,
    fallback_enabled: bool,
}

impl AudioProcessor {
    pub fn process(&self, audio_data: &[u8], format: AudioFormat) 
        -> Result<ProcessedAudio> 
    {
        // PASO 1: Validar formato
        self.validate_format(format)?;
        
        // PASO 2: TranscripciÃ³n (STUB en v1.0)
        // âš ï¸ PROBLEMA: Hardcoded message
        let simulated_text = format!(
            "[AUDIO TRANSCRIPTION STUB] Audio de {} bytes en formato {:?}. \
            En v2.0 se integrarÃ¡ Whisper API para transcripciÃ³n real.",
            audio_data.len(),
            format
        );
        
        // PASO 3: Detectar idioma (HEURÃSTICA SIMPLE)
        let language = self.detect_language(&simulated_text)?;
        
        // PASO 4: Extraer emociones vocales (STUB)
        let vocal_emotion = self.analyze_vocal_emotion(audio_data)?;
        
        Ok(ProcessedAudio {
            text: simulated_text,
            language,
            confidence: 0.85,  // âš ï¸ HARDCODED
            vocal_emotion,
        })
    }
    
    fn detect_language(&self, text: &str) -> Result<Language> {
        // âš ï¸ PROBLEMA: Hardcoded espaÃ±ol/inglÃ©s
        let spanish_words = ["el", "la", "de", "que", "es", "por", "para", "con"];
        let english_words = ["the", "is", "are", "was", "were", "have", "has"];
        
        let spanish_count = spanish_words.iter()
            .filter(|w| text.to_lowercase().contains(*w))
            .count();
            
        let english_count = english_words.iter()
            .filter(|w| text.to_lowercase().contains(*w))
            .count();
        
        if spanish_count > english_count {
            Ok(Language::Spanish)
        } else {
            Ok(Language::English)
        }
    }
}
```

**ğŸ”´ PROBLEMAS IDENTIFICADOS:**

1. **Sesgos culturales:**
   - Solo espaÃ±ol/inglÃ©s hardcoded
   - Â¿QuÃ© pasa con francÃ©s, mandarÃ­n, Ã¡rabe, hindi?
   - Lista fija â†’ No escalable

2. **Stub no funcional:**
   - Whisper API no conectado
   - Mensaje hardcoded â†’ confunde al sistema
   - No es "lienzo en blanco"

3. **Umbrales arbitrarios:**
   - `confidence: 0.85` â†’ Â¿Por quÃ© 0.85?
   - No adaptable a diferentes usuarios

---

### ğŸ“ CAPA 3: TEXT PROCESSOR

```rust
// src/sensory_engine/mod.rs (lÃ­neas 100-180)

pub struct TextProcessor {
    sentiment_analyzer: SentimentAnalyzer,
    entity_recognizer: EntityRecognizer,
}

impl TextProcessor {
    pub fn process(&self, text: &str) -> Result<ProcessedText> {
        // PASO 1: Limpiar texto
        let cleaned = self.clean_text(text);
        
        // PASO 2: Detectar idioma (mismo problema que audio)
        let language = self.detect_language(&cleaned)?;
        
        // PASO 3: AnÃ¡lisis de sentimiento
        let sentiment = self.analyze_sentiment(&cleaned)?;
        
        // PASO 4: Reconocimiento de entidades
        let entities = self.recognize_entities(&cleaned)?;
        
        // PASO 5: ExtracciÃ³n de intenciÃ³n
        let intent = self.extract_intent(&cleaned)?;
        
        Ok(ProcessedText {
            cleaned_text: cleaned,
            language,
            sentiment,
            entities,
            intent,
        })
    }
    
    fn analyze_sentiment(&self, text: &str) -> Result<Sentiment> {
        // âš ï¸ PROBLEMA: HeurÃ­stica simple hardcoded
        let positive_words = ["bueno", "excelente", "genial", "perfecto", "bien"];
        let negative_words = ["malo", "terrible", "horrible", "error", "problema"];
        
        let positive_count = positive_words.iter()
            .filter(|w| text.to_lowercase().contains(*w))
            .count();
            
        let negative_count = negative_words.iter()
            .filter(|w| text.to_lowercase().contains(*w))
            .count();
        
        let score = if positive_count > negative_count {
            0.7  // âš ï¸ HARDCODED positivo
        } else if negative_count > positive_count {
            0.3  // âš ï¸ HARDCODED negativo
        } else {
            0.5  // âš ï¸ HARDCODED neutral
        };
        
        Ok(Sentiment {
            valence: score,
            arousal: 0.5,  // âš ï¸ STUB
            dominance: 0.5,  // âš ï¸ STUB
        })
    }
}
```

**ğŸ”´ PROBLEMAS IDENTIFICADOS:**

1. **Listas estÃ¡ticas de palabras:**
   - `positive_words`, `negative_words` hardcoded
   - Solo espaÃ±ol â†’ sesgo cultural
   - No captura contexto ("no es malo" = positivo?)

2. **Valores mÃ¡gicos:**
   - `0.7`, `0.3`, `0.5` â†’ Â¿De dÃ³nde vienen?
   - No hay justificaciÃ³n matemÃ¡tica
   - Usuario no puede configurar

3. **Arousal y Dominance STUB:**
   - Siempre 0.5 (neutral)
   - No refleja realidad emocional

---

### ğŸ–¼ï¸ CAPA 4: VISUAL PROCESSOR

```rust
// src/sensory_engine/mod.rs (lÃ­neas 185-240)

pub struct VisualProcessor {
    vision_api_key: String,
    ocr_enabled: bool,
}

impl VisualProcessor {
    pub fn process(&self, image: &[u8], format: ImageFormat) 
        -> Result<ProcessedVisual> 
    {
        // PASO 1: Validar imagen
        self.validate_image(image, format)?;
        
        // PASO 2: DescripciÃ³n de escena (STUB)
        // âš ï¸ PROBLEMA: Hardcoded stub
        let description = format!(
            "[VISUAL ANALYSIS STUB] Imagen de {} bytes en formato {:?}. \
            En v2.0 se integrarÃ¡ Vision API (CLIP/GPT-4 Vision).",
            image.len(),
            format
        );
        
        // PASO 3: OCR si hay texto (STUB)
        let extracted_text = if self.ocr_enabled {
            self.extract_text_ocr(image)?
        } else {
            None
        };
        
        // PASO 4: Detectar objetos (STUB)
        let objects = vec![]; // âš ï¸ STUB vacÃ­o
        
        // PASO 5: AnÃ¡lisis emocional de imagen (STUB)
        let visual_sentiment = Sentiment {
            valence: 0.5,  // âš ï¸ NEUTRAL siempre
            arousal: 0.5,
            dominance: 0.5,
        };
        
        Ok(ProcessedVisual {
            description,
            extracted_text,
            objects,
            sentiment: visual_sentiment,
        })
    }
}
```

**ğŸ”´ PROBLEMAS IDENTIFICADOS:**

1. **Todo es STUB:**
   - Vision API no conectado
   - OCR no implementado
   - Object detection vacÃ­o

2. **Hardcoded messages:**
   - DescripciÃ³n es texto fijo
   - No procesa imagen real

3. **Sentiment siempre neutral:**
   - No analiza contenido emocional de imagen
   - Pierde informaciÃ³n valiosa

---

### ğŸ§¬ CAPA 5: NORMALIZATION ENGINE

```rust
// src/sensory_engine/mod.rs (lÃ­neas 245-320)

pub struct NormalizationEngine {
    emotion_detector: EmotionDetector,
    context_builder: ContextBuilder,
}

impl NormalizationEngine {
    pub fn normalize(&self, processed: ProcessedInput) 
        -> Result<NormalizedInput> 
    {
        // PASO 1: Unificar texto
        let unified_text = match processed {
            ProcessedInput::Audio(audio) => audio.text,
            ProcessedInput::Text(text) => text.cleaned_text,
            ProcessedInput::Visual(visual) => visual.description,
        };
        
        // PASO 2: Detectar emociones FINALES
        let emotions = self.detect_emotions(&unified_text)?;
        
        // PASO 3: Extraer entidades unificadas
        let entities = self.extract_all_entities(&unified_text)?;
        
        // PASO 4: Calcular intenciÃ³n global
        let intent = self.calculate_intent(&unified_text, &emotions)?;
        
        // PASO 5: Construir metadatos
        let metadata = self.build_metadata(processed)?;
        
        Ok(NormalizedInput {
            text: unified_text,
            language: metadata.language,
            emotions,
            entities,
            intent,
            metadata,
        })
    }
    
    fn detect_emotions(&self, text: &str) -> Result<EmotionVector> {
        // âš ï¸ PROBLEMA: Hardcoded umbrales
        let valence = if text.contains("feliz") || text.contains("alegre") {
            0.8  // âš ï¸ HARDCODED
        } else if text.contains("triste") || text.contains("deprimido") {
            0.2  // âš ï¸ HARDCODED
        } else {
            0.5
        };
        
        Ok(EmotionVector {
            valence,
            arousal: 0.5,  // âš ï¸ STUB
            dominance: 0.5,  // âš ï¸ STUB
            certainty: 0.7,  // âš ï¸ HARDCODED
        })
    }
}
```

**ğŸ”´ PROBLEMAS IDENTIFICADOS:**

1. **DetecciÃ³n emocional primitiva:**
   - Solo busca palabras especÃ­ficas
   - No considera contexto
   - No usa modelos matemÃ¡ticos

2. **Arousal/Dominance ignorados:**
   - Siempre 0.5 (neutral)
   - Pierde informaciÃ³n dimensional

3. **Certainty arbitrario:**
   - `0.7` sin justificaciÃ³n
   - No refleja confianza real

---

### ğŸ“ CAPA 6: CONTEXT TOKEN 7D BUILDER

```rust
// src/sensory_engine/mod.rs (lÃ­neas 325-390)

impl SensoryEngine {
    pub fn to_context_token_7d(&self, normalized: NormalizedInput) 
        -> Result<ContextToken7D> 
    {
        Ok(ContextToken7D {
            // DimensiÃ³n 1: TEMPORAL
            temporal: TemporalDimension {
                timestamp: Utc::now(),
                sequence: self.sequence_counter.fetch_add(1, Ordering::SeqCst),
                lifecycle_hours: 168,  // 7 dÃ­as
            },
            
            // DimensiÃ³n 2: SEMÃNTICA
            semantic: SemanticDimension {
                text: normalized.text,
                language: normalized.language,
                embeddings: self.generate_embeddings(&normalized.text)?,
                keywords: self.extract_keywords(&normalized.text)?,
            },
            
            // DimensiÃ³n 3: CONTEXTUAL
            contextual: ContextualDimension {
                session_id: self.current_session_id.clone(),
                user_id: self.current_user_id.clone(),
                markers: normalized.metadata.context_markers,
            },
            
            // DimensiÃ³n 4: RELACIONAL
            relational: RelationalDimension {
                parent_tokens: vec![],  // Se llena despuÃ©s
                child_tokens: vec![],
                related_entities: normalized.entities,
            },
            
            // DimensiÃ³n 5: EMOCIONAL
            emotional: EmotionalDimension {
                valence: normalized.emotions.valence,
                arousal: normalized.emotions.arousal,
                dominance: normalized.emotions.dominance,
                certainty: normalized.emotions.certainty,
            },
            
            // DimensiÃ³n 6: INTENCIONAL
            intentional: IntentionalDimension {
                intent: normalized.intent,
                goal: self.infer_goal(&normalized)?,
                action: self.suggest_action(&normalized)?,
            },
            
            // DimensiÃ³n 7: BIOGRÃFICA
            biographical: BiographicalDimension {
                user_history: self.get_user_history()?,
                preferences: self.get_user_preferences()?,
                expertise_level: self.calculate_expertise()?,
            },
        })
    }
}
```

**âœ… FORTALEZAS:**

1. **Estructura dimensional sÃ³lida:**
   - Las 7 dimensiones bien definidas
   - Mapeo claro de normalized â†’ 7D

2. **IntegraciÃ³n con biografÃ­a:**
   - User history considerado
   - Preferences aplicadas

**âš ï¸ LIMITACIONES:**

1. **Dependencia de datos normalizados:**
   - Si normalizaciÃ³n es mala (hardcoded), 7D tambiÃ©n sufre
   - Garbage in, garbage out

---

## ğŸ”¥ PROBLEMAS CRÃTICOS IDENTIFICADOS

### 1. **"LIENZO PRE-PINTADO"** ğŸ¨âŒ

```rust
// Ejemplo del problema:
let spanish_words = ["el", "la", "de", "que", "es"];  // âš ï¸ Solo espaÃ±ol
let positive_words = ["bueno", "excelente"];  // âš ï¸ Solo espaÃ±ol
let confidence = 0.85;  // âš ï¸ Valor mÃ¡gico

// Esto hace que BitÃ¡cora estÃ© SESGADA
// NO es "lienzo en blanco" para cualquier humano
```

**Impacto:**
- âŒ Usuario japonÃ©s â†’ mala detecciÃ³n de idioma
- âŒ Usuario Ã¡rabe â†’ sentimiento incorrecto
- âŒ Usuario con diferentes umbrales â†’ confianza fija

---

### 2. **MÃ‰TODOS MATEMÃTICOS MEZCLADOS** ğŸ§®âŒ

```rust
// Bayes, Fourier, Shannon... todos en el mismo archivo
// NO hay tributo explÃ­cito
// NO son reutilizables
```

**DeberÃ­a ser:**

```
src/sensory_engine/
â”œâ”€ methods/
â”‚  â”œâ”€ bayesian_inference.rs     // Tributo: Thomas Bayes
â”‚  â”œâ”€ fourier_transform.rs      // Tributo: Joseph Fourier
â”‚  â”œâ”€ entropy_calculation.rs    // Tributo: Claude Shannon
â”‚  â””â”€ markov_chains.rs          // Tributo: Andrey Markov
```

---

### 3. **NO HAY TEMPLATES** ğŸ“âŒ

**Lo que hay:**
```rust
let spanish_words = [...];  // Hardcoded en cÃ³digo
```

**Lo que deberÃ­a ser:**
```toml
# templates/sensory/language_detection.toml
[metadata]
method = "bayesian_ngram_analysis"
tribute_to = "Statistical NLP"

[parameters]
supported_languages = ["es", "en", "fr", "de", "pt", "it", "zh", "ar", "hi"]
min_confidence = 0.6
ngram_size = 3

[training_data]
source = "user_provided"  # Usuario aporta corpus
path = "~/.bitacora/training/languages/"
```

**Usuario puede editar sin recompilar** âœ…

---

## âœ¨ SOLUCIÃ“N: REFACTOR v2.0

### ğŸ—ï¸ NUEVA ESTRUCTURA

```
src/sensory_engine/
â”œâ”€ mod.rs                           # Orquestador PURO
â”œâ”€ processors/
â”‚  â”œâ”€ audio/
â”‚  â”‚  â”œâ”€ mod.rs
â”‚  â”‚  â”œâ”€ whisper_processor.rs       # Tributo: OpenAI Whisper
â”‚  â”‚  â”œâ”€ fourier_analyzer.rs        # Tributo: Joseph Fourier (espectrogramas)
â”‚  â”‚  â””â”€ vocal_emotion_detector.rs  # Tributo: Paralinguistics research
â”‚  â”œâ”€ text/
â”‚  â”‚  â”œâ”€ mod.rs
â”‚  â”‚  â”œâ”€ tokenizer.rs               # Tributo: BPE/WordPiece (Hugging Face)
â”‚  â”‚  â”œâ”€ language_detector.rs       # Tributo: Statistical NLP
â”‚  â”‚  â”œâ”€ sentiment_analyzer.rs      # Tributo: VADER/TextBlob
â”‚  â”‚  â””â”€ entity_recognizer.rs       # Tributo: spaCy NER
â”‚  â””â”€ visual/
â”‚     â”œâ”€ mod.rs
â”‚     â”œâ”€ vision_processor.rs        # Tributo: CLIP (OpenAI)
â”‚     â”œâ”€ ocr_engine.rs              # Tributo: Tesseract/PaddleOCR
â”‚     â””â”€ scene_analyzer.rs          # Tributo: Object Detection (YOLO)
â”œâ”€ methods/
â”‚  â”œâ”€ bayesian_inference.rs         # Tributo: Thomas Bayes (1701-1761)
â”‚  â”œâ”€ fourier_transform.rs          # Tributo: Joseph Fourier (1768-1830)
â”‚  â”œâ”€ markov_chains.rs              # Tributo: Andrey Markov (1856-1922)
â”‚  â”œâ”€ entropy_calculation.rs        # Tributo: Claude Shannon (1916-2001)
â”‚  â”œâ”€ cosine_similarity.rs          # Tributo: Vector Space Models
â”‚  â””â”€ gaussian_mixture.rs           # Tributo: Carl Friedrich Gauss (1777-1855)
â””â”€ templates/
   â”œâ”€ loader.rs
   â””â”€ validator.rs
```

### ğŸ“‹ TEMPLATES EXTERNOS

```
templates/sensory/
â”œâ”€ audio/
â”‚  â”œâ”€ whisper_config.toml
â”‚  â”œâ”€ emotion_voice_analysis.toml
â”‚  â””â”€ music_harmony_detection.toml
â”œâ”€ text/
â”‚  â”œâ”€ language_detection.toml
â”‚  â”œâ”€ sentiment_analysis.toml
â”‚  â”œâ”€ entity_recognition.toml
â”‚  â””â”€ emotion_text_analysis.toml
â””â”€ visual/
   â”œâ”€ vision_config.toml
   â”œâ”€ ocr_config.toml
   â””â”€ scene_understanding.toml
```

---

## ğŸ¯ EJEMPLO: TEMPLATE DINÃMICO

### Archivo: `templates/sensory/text/language_detection.toml`

```toml
[metadata]
name = "Language Detection Template"
version = "2.0.0"
method = "bayesian_ngram_analysis"
tribute_to = "Statistical NLP Methods"
last_updated = "2025-10-28"

[parameters]
# Usuario puede agregar idiomas sin tocar cÃ³digo
supported_languages = [
    "es",  # EspaÃ±ol
    "en",  # InglÃ©s
    "fr",  # FrancÃ©s
    "de",  # AlemÃ¡n
    "pt",  # PortuguÃ©s
    "it",  # Italiano
    "zh",  # Chino
    "ar",  # Ãrabe
    "hi",  # Hindi
    "ja",  # JaponÃ©s
    "ko",  # Coreano
]

min_confidence = 0.6
ngram_size = 3
use_stopwords = true

[method.bayesian]
algorithm = "bayesian_ngram_frequency"
prior_source = "user_history"  # O "uniform"
update_strategy = "online_learning"

[training_data]
source = "user_provided"
path = "~/.bitacora/training/languages/"
auto_update = true

[fallback]
default_language = "user_preferred"  # Configurado en perfil
notify_user_on_low_confidence = true
min_confidence_for_notification = 0.5
```

### CÃ³digo que lo usa:

```rust
// src/sensory_engine/processors/text/language_detector.rs

//! # Language Detector
//! 
//! **Tributo a:** Statistical Natural Language Processing
//! 
//! **MÃ©todo:** Bayesian N-gram Frequency Analysis
//! 
//! P(Lang|Text) = P(Text|Lang) * P(Lang) / P(Text)
//! 
//! donde:
//! - P(Lang): Prior (histÃ³rico del usuario o uniforme)
//! - P(Text|Lang): Likelihood (n-gramas en corpus)
//! - P(Text): Evidence (normalizaciÃ³n)

use crate::sensory_engine::templates::TemplateLoader;
use crate::sensory_engine::methods::bayesian_inference::BayesianInference;

pub struct LanguageDetector {
    template: LanguageDetectionTemplate,
    bayes: BayesianInference,
    training_corpus: HashMap<String, LanguageCorpus>,
}

impl LanguageDetector {
    pub fn new() -> Result<Self> {
        // Cargar template dinÃ¡mico
        let template = TemplateLoader::load("text/language_detection.toml")?;
        
        // Cargar corpus de entrenamiento
        let corpus = Self::load_training_data(&template.training_data.path)?;
        
        Ok(Self {
            template,
            bayes: BayesianInference::new(),
            training_corpus: corpus,
        })
    }
    
    pub fn detect(&self, text: &str) -> Result<LanguageDetection> {
        // Extraer n-gramas
        let ngrams = self.extract_ngrams(text, self.template.parameters.ngram_size);
        
        let mut language_scores = HashMap::new();
        
        // Para cada idioma soportado (desde template)
        for lang in &self.template.parameters.supported_languages {
            // Calcular P(Text|Lang) - likelihood
            let likelihood = self.calculate_ngram_likelihood(&ngrams, lang)?;
            
            // Obtener P(Lang) - prior (histÃ³rico usuario)
            let prior = self.get_language_prior(lang)?;
            
            // Aplicar Teorema de Bayes
            let posterior = self.bayes.compute_posterior(prior, likelihood, 1.0);
            
            language_scores.insert(lang.clone(), posterior);
        }
        
        // Seleccionar idioma con mayor probabilidad
        let (detected_lang, confidence) = language_scores
            .iter()
            .max_by(|a, b| a.1.partial_cmp(b.1).unwrap())
            .map(|(lang, score)| (lang.clone(), *score))
            .unwrap();
        
        // Verificar umbral de confianza
        if confidence < self.template.parameters.min_confidence {
            if self.template.fallback.notify_user_on_low_confidence {
                // Notificar usuario
                log::warn!("Low confidence language detection: {} ({:.2})", 
                          detected_lang, confidence);
            }
            
            // Usar fallback
            return Ok(LanguageDetection {
                language: self.template.fallback.default_language.clone(),
                confidence: 0.0,
                fallback_used: true,
            });
        }
        
        Ok(LanguageDetection {
            language: detected_lang,
            confidence,
            fallback_used: false,
        })
    }
    
    fn extract_ngrams(&self, text: &str, n: usize) -> Vec<String> {
        // ImplementaciÃ³n n-grams
        text.chars()
            .collect::<Vec<_>>()
            .windows(n)
            .map(|w| w.iter().collect())
            .collect()
    }
    
    fn calculate_ngram_likelihood(&self, ngrams: &[String], lang: &str) 
        -> Result<f64> 
    {
        let corpus = self.training_corpus.get(lang)
            .ok_or_else(|| anyhow!("No corpus for language: {}", lang))?;
        
        let mut likelihood = 1.0;
        for ngram in ngrams {
            let frequency = corpus.ngram_frequency.get(ngram).unwrap_or(&0.0);
            likelihood *= frequency;
        }
        
        Ok(likelihood)
    }
    
    fn get_language_prior(&self, lang: &str) -> Result<f64> {
        match self.template.method.bayesian.prior_source.as_str() {
            "user_history" => {
                // Obtener histÃ³rico del usuario
                let user_langs = UserProfile::get_language_distribution()?;
                Ok(user_langs.get(lang).unwrap_or(&0.1))  // Uniform fallback
            },
            "uniform" => {
                Ok(1.0 / self.template.parameters.supported_languages.len() as f64)
            },
            _ => Err(anyhow!("Unknown prior source"))
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_spanish_detection() {
        let detector = LanguageDetector::new().unwrap();
        let result = detector.detect("Hola, Â¿cÃ³mo estÃ¡s?").unwrap();
        assert_eq!(result.language, "es");
        assert!(result.confidence > 0.8);
    }
    
    #[test]
    fn test_multilanguage_support() {
        let detector = LanguageDetector::new().unwrap();
        
        // EspaÃ±ol
        assert_eq!(detector.detect("Buenos dÃ­as").unwrap().language, "es");
        
        // InglÃ©s
        assert_eq!(detector.detect("Good morning").unwrap().language, "en");
        
        // FrancÃ©s
        assert_eq!(detector.detect("Bonjour").unwrap().language, "fr");
        
        // Ãrabe
        assert_eq!(detector.detect("Ù…Ø±Ø­Ø¨Ø§").unwrap().language, "ar");
        
        // Chino
        assert_eq!(detector.detect("ä½ å¥½").unwrap().language, "zh");
    }
}
```

---

## ğŸ¯ VENTAJAS DEL REFACTOR

### âœ… 1. Lienzo en Blanco Real

```toml
# Usuario puede editar templates/sensory/text/language_detection.toml
[parameters]
supported_languages = ["tlh"]  # Â¡Klingon! ğŸ––
min_confidence = 0.3  # MÃ¡s permisivo

# SIN recompilar cÃ³digo
```

### âœ… 2. Tributos MatemÃ¡ticos ExplÃ­citos

```rust
//! # bayesian_inference.rs
//! 
//! **Tributo a:** Thomas Bayes (1701-1761)
//! **Paper original:** "An Essay towards solving a Problem in the Doctrine of Chances" (1763)
//! **AplicaciÃ³n:** Language detection, sentiment analysis, intent classification

// MÃ©todo matemÃ¡tico PURO - reutilizable
```

### âœ… 3. Hot-Reload

```rust
// Usuario edita template â†’ Sistema detecta cambio â†’ Recarga automÃ¡ticamente
// SIN reiniciar BitÃ¡cora
```

### âœ… 4. Escalabilidad

```
Agregar nuevo idioma:
1. AÃ±adir "ru" a supported_languages
2. Agregar corpus en ~/.bitacora/training/languages/ru/
3. Â¡Listo!

NO TOCAR CÃ“DIGO
```

---

## ğŸ“Š COMPARACIÃ“N v1.0 vs v2.0

| Aspecto | v1.0 MonolÃ­tico | v2.0 Modular |
|---------|-----------------|--------------|
| **Idiomas** | 2 (es, en) hardcoded | N (usuario configura) |
| **MÃ©todos matemÃ¡ticos** | Mezclados en mod.rs | Archivos separados con tributo |
| **ConfiguraciÃ³n** | Recompilar cÃ³digo | Editar TOML (hot-reload) |
| **Sesgos culturales** | Alto (solo espaÃ±ol) | Bajo (multiidioma) |
| **Escalabilidad** | Baja | Alta |
| **Testabilidad** | Media | Alta (mÃ©todos puros) |
| **DocumentaciÃ³n** | Escasa | Tributos explÃ­citos |
| **Lienzo en blanco** | âŒ Pre-pintado | âœ… Usuario define |
| **Complejidad cÃ³digo** | ~600 lÃ­neas monolÃ­ticas | ~200 lÃ­neas/mÃ³dulo |

---

## ğŸ¯ CONCLUSIÃ“N

**Estado Actual (v1.0):**
- âœ… **Funcional** para casos bÃ¡sicos
- âš ï¸ **Sesgado** culturalmente (espaÃ±ol/inglÃ©s)
- âŒ **No escalable** (hardcoded logic)
- âŒ **No es "lienzo en blanco"** (pre-pintado)

**Estado Futuro (v2.0 - FASE 6 REFACTOR):**
- âœ… **Modular** (processors + methods separados)
- âœ… **Templates dinÃ¡micos** (usuario configura)
- âœ… **Tributos matemÃ¡ticos** (Bayes, Fourier, Shannon...)
- âœ… **Hot-reload** (sin recompilar)
- âœ… **Multiidioma** (escalable a N idiomas)
- âœ… **Lienzo en blanco REAL** (usuario define todo)

---

**PrÃ³ximos pasos:**
1. âœ… Tareas agregadas a CHECKLIST_V2.md (FASE 6)
2. âœ… Estructura detallada en CHECKLIST_TREE_V2.md
3. ğŸ¯ **Implementar despuÃ©s de Beta** (Post 88%)
4. ğŸ”¥ **Prioridad:** Tributos matemÃ¡ticos primero

---

*Generado: 2025-10-28 15:45h*  
*Sistema BitÃ¡cora v1.0 - ZOOM Ingestion Analysis*  
*"De lienzo pre-pintado a lienzo en blanco"* ğŸ¨âœ¨
